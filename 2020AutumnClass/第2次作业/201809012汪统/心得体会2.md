##本次课我学习了线性回归在神经网络中的应用，通过学习单变量线性回归的问题，我又了解到了几种将要研究问题转换为线性回归问题的方：① 最小二乘法② 梯度下降法③ 简单的神经网络法④ 更通用的神经网络算法。从这些方法的基本原理和python实现方面，我基本明白了这些方法的实现过程。另外一节课，老师讲解了梯度下降的三种形式，即最小二乘法、梯度下降法、神经网络法。其中，神将网络法是我们重点需要掌握的，神经网络法使用一个崭新的编程模型，即以神经元为中心的代码结构设计，它对我们学习神经网络是很有用的。数据归一化是深度学习的必要步骤之一，将普通问题的数值归一是解决神经网络问题的重要之处，这样便于我们更好的研究问题。
##在这一次课的学习中，我弄清楚了神经网络中的线性分类问题，神经网络的一个重要功能就是分类，现实世界中的分类任务复杂多样，但万变不离其宗，我们都可以用同一种模式的神经网络来处理。这足以可见分类问题在神经网络中的重要作用，本次课老师主要讲解了线性二分类的原理，实现，训练过程，推理过程等等，在线性多分类问题中主要讲解了一对一、一对多、多对多的问题，以及多分类函数softmax的作用。总的来说，本次课来说主要为我们讲解了神经网络中的一个重要问题---分类。解决了分类问题，可以说解决了一个大问题，这也是为什么分类在神经网络中非常重要。
##通过这次课的学习，我对神经网络仿佛更感兴趣了，神经网络的研究是当今的热点，这是一门前沿的技术，虽然有时候我对其中的一些知识并不是很懂，但通过一些网络资料，我渐渐明白了，很多的数学知识是比较抽象的，要理解还是需要一定的数学基础，所以我觉得有一个好的数学功底是非常重要的。但是我会不断加强自己的数学基础，为学好这门课做好铺垫。