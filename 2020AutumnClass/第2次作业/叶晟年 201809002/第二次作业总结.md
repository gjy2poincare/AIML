### 总结

通过step2的学习，我知道了什么是最小二乘法，梯度下降法以及神经网络法。若使用穷举法，将会造成一个几乎不可能实现的计算量。第二个想到的方法就是微分求导。通过将损失函数进行全微分，取全微分方程为零或较小的点，即可得到理想参数。

通过step 3的学习。我知道了线性分类。其中的二分类函数印象最深。就好比这个函数“Logistic Function” 既是激活又是二分类函数。不可以混为一谈。虽然有些书是把他们混在一起，但是做学术还是要有严谨性的。

龚老师说过“只要你数学学的好，那么计算机也不成问题”，现在深有感触了。本次课的学习又加深了我对神经网络的理解，为之后更加深层次的学习打下了坚实的基础。