1基本概念
2线性回归
3线性分类
4非线性回归
5非线性分类
6模型的推理与部署
7深度神经网络
8卷积神经网络
9循环神经网络

图1-3 人工智能发展史
![](2020-10-05-22-10-57.png)
从图中我们可以看出，人工智能的发展，有这样起伏的模式：

研究（包括技术）取得进展。
研究的进展让人们看到人工智能的潜力，产生非常乐观的期望，例如在1958年到1970年间科学家对人工智能各种突破的预计，当然他们的绝大多数预计都太乐观了。
上述过高的期望让产业界开始热情地开发各种应用。
但应用未能全部满足期望，于是人工智能行业进入低谷，直到下一波研究和技术取得突破性进展。在2007年之后，是大规模的数据和廉价的计算能力，让神经网络技术再度兴起，成为AI领域的明星技术。

1.1 人工智能的定义

第一个层面，人们对人工智能的期待可以分为：
智能地把某件特定的事情做好，在某个领域增强人类的智慧，这种方式又叫做智能增强——像搜索引擎，自动语言翻译，某个领域的智能助手那样的程序，帮助人类完成某种特定任务。这也叫做“弱人工智能”，或者“狭义人工智能”。
像人类一样能认知，思考，判断：模拟人类的智能——像人类一样能认知，思考，判断的智能软件。这是人工智能学科一开始就有的梦想。这样的智能也叫做“通用人工智能”（Artificial General Intelligence， AGI）， 或“强人工智能”。对于这样的人工智能，科幻小说有很多描写，也有一些研究，但是在实际的应用还没有什么突破。有学者认为，AGI是不可能通过目前人们编程程序的方式实现的$^{[1]}$。尽管如此，社会上还是有人担忧有一天电脑的AGI会超过人类的智能，人类再也赶不上电脑，从而永远受制于电脑。
第二个层面，从技术的特点来看。
要实现某种狭义的人工智能，我们很自然地想到，如果我们能让运行程序的电脑来学习并自动掌握某些规律，那该多好啊，这就是“机器学习”。机器学习在几十年的发展历史中，产生了很多技术，

机械的三种学习类型

1监督学习（Supervised Learning）

通过标注的数据来学习，例如，程序通过学习标注了正确答案的手写数字的图像数据，它就能认识其他的手写数字。

2无监督学习（Unsupervised Learning）

通过没有标注的数据来学习。这种算法可以发现数据中自然形成的共同特性（聚类），可以用来发现不同数据之间的联系，例如，买了商品A的顾客往往也购买了商品B。

3强化学习（Reinforcement Learning）

我们可以让程序选择和它的环境互动（例如玩一个游戏），环境给程序的反馈是一些“奖励”（例如游戏中获得高分），程序要学习到一个模型，能在这种环境中得到高的分数，不仅是当前局面要得到高分，而且最终的结果也要是高分才行。
随着数据的丰富和机器算力的增强，人们不断增加神经网络的层次数目，相邻层次之间的输入输出由非线性函数来控制，这就产生了DNN（深度神经网络）。DNN在最近十年给人工智能领域带来了新的生机，并在图像分类、语音识别、自然语言处理等方面取得了重大突破。

随着人们不断的调整网络结构，DNN也演变成许多不同的网络拓扑结构，例如CNN（卷积神经网络），RNN（循环神经网络），LSTM（长期短期记忆），GAN（生成对抗网络），Transfer Learning（迁移学习）等，这些模型还在不断演化中。

训练AI模型，需要一系列专门的工具，业界有不少成熟的训练平台（TensorFlow，PyTorch，MXNet等），这些平台也在不断演化，支持新的模型，提高训练的效率，改进易用性，等等。当然我们也可以自己开发平台来训练，本书的大部分章节就是带领读者自己动手打造一个小型的开发平台。

第三个层面，从应用的角度来看，我们看到狭义人工智能在各个领域都取得了很大的成果。
一种是标杆式的任务，例如ImageNet，考察AI模型能否识别图像的类别，2015年，AI取得了超过人类的成果。在其它的领域中，我们也看到了AI取得了达到或超过人类最高水平的成绩
从这个角度说，本书的名字“智能之门”也只能说明这本书是进入人工智能领域的一个小门而已。 还有其他很多门道。

那么，一个典型的机器学习的模型是怎么得来的，又是怎么在应用中使用的呢？以MNIST数据集为例，整体流程如图所示。
![](2020-10-05-22-23-46.png)


1.2 范式的演化
在很多人眼里，AI来势汹汹，看样子会颠覆很多领域，这些新技术的出现有规律可循么？还会有什么别的技术突然出现让我们措手不及？这当然是有规律可循的。人类一直在试图了解客观规律，这种科学历史上发生了几次颠覆性的改变（范式转换）呢？我们通过Jim Gray的著作science paradigms可以看到，现在谈论的AI大潮就是属于data exploration这个范式转换的一部分。图1-8是Jim Gray著作中的插图，概述了范式演化的几个阶段，接下来我们将一一进行介绍。
![](2020-10-05-22-26-45.png)

范式演化的四个阶段

第一阶段：经验
从几千年前到几百年前，人们描述自然现象，归纳总结一些规律。

人类最早的科学研究，主要以记录和描述自然现象为特征，不妨称之为称为“经验归纳”（第一范式）。人们看到自然现象，凭着自己的体验总结一些规律，并把规律推广到其他领域。这些规律通常是定性的，不是定量的。有时看似符合直觉，其实原理是错误的；有时在某个局部有效，但是推广到其他领域则不能适用；有些论断来自权威，导致错误总结也流传了很多年无人挑战。例如，我们看到日月星辰都围绕我们转，地心说很自然就产生了； 我们在生活中观察不同质量的物体运动的情况，也凭直觉推断“物体的下落速度和重量成正比”。人们对于不同的观点，也没有严谨地定义试验来证明。

第二阶段：理论
这一阶段，科学家们开始明确定义，速度是什么，质量是什么，化学元素是什么（不再是五行和燃素）……也开始构建各种模型，在模型中尽量撇除次要和无关因素，例如我们在中学的物理实验中，要假设“斜面足够光滑，无摩擦力”，“空气阻力可以忽略不计”，等等。在这个理论演算（Theoretical）阶段，以伽利略为代表的科学家，开启了现代科学之门。他在比萨斜塔做的试验（图1-9）推翻了两千多年来大家想当然的“定律”。

第三阶段：计算仿真
从二十世纪中期开始，利用电子计算机对科学实验进行模拟仿真的模式得到迅速普及，人们可以对复杂现象通过模拟仿真，推演更复杂的现象，典型案例如模拟核试验、天气预报等。这样计算机仿真越来越多地取代实验，逐渐成为科研的常规方法。科学家先定义问题，确认假设，再利用数据进行分析和验证。

第四阶段：数据探索
最后我们到了“数据探索”（Data Exploration）阶段。在这个阶段，科学家收集数据，分析数据，探索新的规律。在深度学习的浪潮中出现的许多结果就是基于海量数据学习得来的。有些数据并不是从现实世界中收集而来，而是由计算机程序自己生成，例如，在AlphaGo算法训练的过程中，它和自己对弈了数百万局，这个数量大大超过了所有记录下来的职业选手棋谱的数量。

梯度下降

从自然现象中理解梯度下降
在大多数文章中，都以“一个人被困在山上，需要迅速下到谷底”来举例，这个人会“寻找当前所处位置最陡峭的地方向下走”。这个例子中忽略了安全因素，这个人不可能沿着最陡峭的方向走，要考虑坡度。

在自然界中，梯度下降的最好例子，就是泉水下山的过程：

水受重力影响，会在当前位置，沿着最陡峭的方向流动，有时会形成瀑布（梯度下降）；
水流下山的路径不是唯一的，在同一个地点，有可能有多个位置具有同样的陡峭程度，而造成了分流（可以得到多个解）；
遇到坑洼地区，有可能形成湖泊，而终止下山过程（不能得到全局最优解，而是局部最优解）。
梯度下降的三要素
1当前点； 
2方向；
3步长。
为什么说是“梯度下降”？
“梯度下降”包含了两层含义：

梯度：函数当前位置的最快上升点；
下降：与导数相反的方向，用数学语言描述就是那个减号。
亦即与上升相反的方向运动，就是下降。

损失函数概念
在各种材料中经常看到的中英文词汇有：误差，偏差，Error，Cost，Loss，损失，代价......意思都差不多，在本书中，使用“损失函数”和“Loss Function”这两个词汇
损失函数的作用
损失函数的作用，就是计算神经网络每次迭代的前向计算结果与真实值的差距，从而指导下一步的训练向正确的方向进行。

如何使用损失函数呢？具体步骤：

用随机值初始化前向计算公式的参数；
代入样本，计算输出的预测值；
用损失函数计算预测值和标签值（真实值）的误差；
根据损失函数的导数，沿梯度最小方向将误差回传，修正前向计算公式中的各个权重值；
进入第2步重复, 直到损失函数值达到一个满意的值就停止迭代。
神经网络中常用的损失函数
均方差函数，主要用于回归

交叉熵函数，主要用于分类

二者都是非负函数，极值在底部，用梯度下降法可以求解。
import numpy as np

def target_function(w,b):
    x = 2*w+3*b
    y=2*b+1
    z=x*y
    return x,y,z

def single_variable(w,b,t):
    print("\nsingle variable: b ----- ")
    error = 1e-5
    while(True):
        x,y,z = target_function(w,b)
        delta_z = z - t
        print("w=%f,b=%f,z=%f,delta_z=%f"%(w,b,z,delta_z))
        if abs(delta_z) < error:
            break
        delta_b = delta_z /63
        print("delta_b=%f"%delta_b)
        b = b - delta_b

    print("done!")
    print("final b=%f"%b)

def single_variable_new(w,b,t):
    print("\nsingle variable new: b ----- ")
    error = 1e-5
    while(True):
        x,y,z = target_function(w,b)
        delta_z = z - t
        print("w=%f,b=%f,z=%f,delta_z=%f"%(w,b,z,delta_z))
        if abs(delta_z) < error:
            break
        factor_b = 2*x+3*y
        delta_b = delta_z/factor_b
        print("factor_b=%f, delta_b=%f"%(factor_b, delta_b))
        b = b - delta_b

    print("done!")
    print("final b=%f"%b)


import numpy as np
import matplotlib.pyplot as plt

def draw_fun(X,Y):
    x = np.linspace(1.2,10)
    a = x*x
    b = np.log(a)
    c = np.sqrt(b)
    plt.plot(x,c)

    plt.plot(X,Y,'x')

    d = 1/(x*np.sqrt(np.log(x**2)))
    plt.plot(x,d)
    plt.show()


def forward(x):
    a = x*x
    b = np.log(a)
    c = np.sqrt(b)
    return a,b,c

def backward(x,a,b,c,y):
    loss = c - y
    delta_c = loss
    delta_b = delta_c * 2 * np.sqrt(b)
    delta_a = delta_b * a
    delta_x = delta_a / 2 / x
    return loss, delta_x, delta_a, delta_b, delta_c

def update(x, delta_x):
    x = x - delta_x
    if x < 1:
        x = 1.1
    return x

if __name__ == '__main__':
    print("how to play: 1) input x, 2) calculate c, 3) input target number but not faraway from c")
    print("input x as initial number(1.2,10), you can try 1.3:")
    line = input()
    x = float(line)
    
    a,b,c = forward(x)
    print("c=%f" %c)
    print("input y as target number(0.5,2), you can try 1.8:")
    line = input()
    y = float(line)

    error = 1e-3

    X,Y = [],[]

    for i in range(20):
        # forward
        print("forward...")
        a,b,c = forward(x)
        print("x=%f,a=%f,b=%f,c=%f" %(x,a,b,c))
        X.append(x)
        Y.append(c)
        # backward
        print("backward...")
        loss, delta_x, delta_a, delta_b, delta_c = backward(x,a,b,c,y)
        if abs(loss) < error:
            print("done!")
            break
        # update x
        x = update(x, delta_x)
        print("delta_c=%f, delta_b=%f, delta_a=%f, delta_x=%f\n" %(delta_c, delta_b, delta_a, delta_x))

    
    draw_fun(X,Y)

    mooc
    神经网络介绍
    传统神经网络结构比较简单，训练时随机初始化输入参数，并开启循环计算输出结果，与实际结果进行比较从而得到损失函数，并更新变量使损失函数结果值极小，当达到误差阈值时即可停止循环神经网络的训练目的是希望能够学习到一个模型，实现输出一个期望的目标值。学习的方式是在外界输入样本的刺激下不断改变网络的连接权值。传统神经网络主要分为一下几类:前馈型神经网络，反馈型神经网络和自组织神经网络。这几类网络具有不同的学习训练算法，可以归结为监督型学习算法和非监督型学习算法.

    BP神经网络
    .BP神经网络训练过程的基本步骤可以归纳如下―初始化网络权值和神经元的阈值，一般通过随机的方式进行初始化-前向传播:计算隐层神经元和输出层神经元的输出-后向传播:根据目标函数公式修正权值wjj·上述过程反复迭代，通过损失函数和成本函数对前向传播结果进行判定，并通过后向传播过程对权重参数进行修正，起到监督学习的作用，一直到满足终止条件为止BP神经网络的核心思想是由后层误差推导前层误差，一层一层的反传，最终获得各层的误差估计，从而得到参数的权重值。由于权值参数的运算量过大，一般采用梯度下降法来实现·所谓梯度下降就是让参数向着梯度的反方向前进一段距离，不断重复，直到梯度接近零时停止。此时，所有的参数恰好达到使损失函数取得最低值的状态，为了避免局部最优，可以采用随机化梯度下降.
 心得体会
通过本星期的AI学习，我明白了BP神经网络的基本原理，我知道了反向传播和梯度下降，通过在慕课平台的学习和老师的讲解对深入学习有了更加深刻的认识，也让我知道了在人类在AI方向的学习还有很长的路要走，同样也告诉我数学是科学的根源，要提升自己的逻辑思维能力。