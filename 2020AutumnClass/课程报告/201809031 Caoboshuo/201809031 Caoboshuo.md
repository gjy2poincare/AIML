# 《人工智能概论》课程考核报告
## 曹博硕
# 学习笔记
### 1.0人工智能发展简史
在判断智能的可能性下，英国科学家图灵提出了图灵测试，如果一台机器能够与人类展开对话而不能被辨别出其机器的身份，那么称这台机器具有智能。

关于聊天机器人是否智能，1980年有学者提出中文房间问题，在房间中一个不会中文，只会英语的人被关在封闭房间，房内有一本英文手册，指示如何处理收到的汉语信息并如何用汉语回复，房间内的人接收外部传入的中文问题，再通过查阅手册回复相应的中文问题，将答案递出。

当房间外的人无法分辨内部传出的中文信息是出自人还是机器之手时，这就被叫做智能。

### 1.1 人工智能的定义
人工智能的分类：
#### 由**期待**进行划分：
 **智能地把某件特定的事情做好，在某个领域增强人类的智慧，这种方式又叫做智能增强**这种人工智能针对于某一方面，在某一特定领域帮助人类完成简单的任务，属于“弱人工智能”，或者叫“狭义人工智能”
**像人类一样能认知，思考，判断：模拟人类的智能**
这种人工智能是人类所憧憬的人工智能，具有和人一样的智慧，思考，可以多维度的处理各种各样的事情，但是这种人工智能基于目前的编程无法实现，也有人对于这样的“强人工智能”怀有担心和疑虑，害怕AI超出人类的控制，从未对人类造成危害，不过目前我们的技术离这个还很远，不需要杞人忧天，很多科幻类影视作品喜欢以这个为题材，描绘人机大战。

#### 由**技术**进行分析
**因为目前所实施的大多是狭义的人工智能，所以优先考虑这种方式，通过对这种方式的分析，可以发现这种技术拥有一些共性：**

1.有一个模型结构（例如逻辑回归，决策树）
2.用训练数据输入模块，获得经验
3.通过不断执行任务并在执行结束后对结果进行分析，重复使结果不断优化，达到一个满意的值。

**对机器学习的方法可以划归三种类型：**
1.监督学习
2.无监督学习
3.强化学习

其中监督学习是通过标注的数据来学习，无监督学习是通过没有标注的数据进行学习，这种方式相较于上一种需要更强的分析能力，可以从数据种找到共同特性，发现不同数据间的联系。强化学习则是在无监督学习的基础上，选择与外界进行互动，环境给程序的反馈，成为对程序学习的实现的评价标准，程序需要学习到一个模型，持续的获得高评价，是程序不断地提升，不断地优化到评价满意的水平。

机器学习领域中，神经元是其中一个重要的方法，每个神经元都与其他神经元相连，同时会向其他神经元发送化学物质，改变其他神经元，当某个神经元的电位超过一定的阈值，它就会被激活，向其他神经元发送化学物质。将神经元搭建起来我们就会构建出一个神经网络。

随着数据的丰富和机器算力的增强，人们可以不断增加神经网络的层次数目，相邻层次之间的输入输出由非线性函数来控制，产生DNN（深度神经网络）。其近十年有巨大成果，包括图像分类、语音识别、自然语言处理等方面。

随着人们不断地调整网络结构，DNN又产生了许多新的结构，例如卷积神经网络，循环神经网络，长期短期记忆，生成对抗网络，迁移学习等。

#### 由取得成果来看
狭义人工智能在各个领域都取得了很大的成果。某些领域中，人工智能的某项能力取得的成绩已经超过了人类的最高水平

如：
-翻译领域（微软的中英翻译超过了人类）
-阅读理解（SQuAD比赛）
-下围棋（2016）德州扑克（2019）

AI在一些领域与其他科技的结合，如计算，数据，云端和物联网终端设备联系，搭建一个支持智能决定的系统，这也可以看作是未来基础设置建设的一个方向，称之为新基建。

在个人用户的角度来看，AI已经走进了我们的生活中，从从跨境旅游的翻译、照片的美颜，甚至是人工换脸等方面，AI已经完美的满足了我们的需求。

未来的软件开发中，程序的开发，和AI模型的开发进行有机的协同，达到一种更好的效果，为用户提供更好的服务，创作更大的价值。

### 1.2 范式的演化 
-**范式的演化阶段：**
1.第一阶段：经验
2.第二阶段：理论
3.第三阶段：计算仿真
4.第四阶段：数据探索

演变过程也是通过感官获取的经验，不断地积累而后获得相应的理论，在通过实验进行对理论地计算仿真，查看验证结果，反过来对理论进行验证，在数据探索阶段，通过数据的回收，通过分析数据，探索新的规律，对AI而言就是不断地学习，不断地总结，不断地获取能力，不断地强化AI，例如ALphaGo。

### 神经网络地基本工作原理介绍
-**神经网络细胞的数学模型**
输入 input
权重 weights
偏移 bias
求和计算 sum
激活函数 activation

**小结**
- 一个神经元可以有多个输入
- 一个神经元只能有一个输出，这个输出可以同时输入给多个神经元。
- 一个神经元的$w$的数量和输入的数量一致。
- 一个神经元只有一个 $b$。
- $w$ 和 $b$ 有人为的初始值，在训练过程中被不断修改。
- $A$ 可以等于 $Z$，即激活函数不是必须有的。
- 一层神经网络中的所有神经元的激活函数必须一致。

**单层神经网络模型**
这是一个单层的神经网络，假设有m个输入，有n个输出。在神经网络中，b到每一个神经元的权值来表示实际的偏移值，（b_1,b_2）,这样便于矩阵运算。也有些把b写成x_0,其实是同一个效果，即把偏移值看作神经元的一个输入。
x_1，x_2,x_3看作是样本数据的三个特征值
w_{11},w_{21},w_{31}是（x_1，x_2,x_3）到n1的权重
w_{12},w_{22},w_{32}是（x_1,x_2,x_3)到n2的权重
b_1是n1的偏移
b_2是n2的偏移

![](https://camo.githubusercontent.com/231032513bc8d84bf9a3f601e200279b1b0f3eee/68747470733a2f2f61696564756769746875623461322e626c6f622e636f72652e77696e646f77732e6e65742f61322d696d616765732f496d616765732f312f4f6e654c617965724e4e2e706e67)

**训练流程**
如图所示

![](https://camo.githubusercontent.com/292b2fbcd6e3351763cab081dd8c02e413f3ba81/68747470733a2f2f61696564756769746875623461322e626c6f622e636f72652e77696e646f77732e6e65742f61322d696d616765732f496d616765732f312f547261696e466c6f772e706e67)

**神经网络的主要功能**
回归/拟合：使得模拟测试出的y值与样本数据形成的曲线距离尽量的小，可以理解为是对样本数据的一种骨架式的抽象。

![](https://camo.githubusercontent.com/3069fea9664ce4873d7cc8c4cf5a17b8c287948a/68747470733a2f2f61696564756769746875623461322e626c6f622e636f72652e77696e646f77732e6e65742f61322d696d616765735c496d616765735c315c7367645f726573756c742e706e67)

分类

通过一个两层的神经网络得到一个非常相似的结果，使得分类误差在满意的范围之内。通过神经网络训练出来的分界线，可以比较完美地把两类样本分开，所以分类可以理解为是对两类或多类样本数据的边界的抽象。

激活函数

人体运动组织和神经网络组织的对比

|人体运动组织|神经网络组织|
|---|---|
|支撑骨骼|网络层次|
|关节|激活函数|
|肌肉韧带|权重参数|
|学习各种运动的动作|前向+反向训练过程|

![](https://camo.githubusercontent.com/497a1caa69069e20853c75c77dedd20bc9a8f978/68747470733a2f2f61696564756769746875623461322e626c6f622e636f72652e77696e646f77732e6e65742f61322d696d616765732f496d616765732f312f4c696e656172767341637469766174696f6e2e706e67)

激活函数相当于对得到的数据进行合理的拟合操作

### 神经网络的三个基本概念
这三个概念是：反向传播，梯度下降，损失函数。

反向传播与梯度下降的基本工作原理：

1. 初始化；
2. 正向计算；
3. 损失函数为我们提供了计算损失的方法；
4. 梯度下降是在损失函数基础上向着损失最小的点靠近而指引了网络权重调整的方向；
5. 反向传播把损失值反向传给神经网络的每一层，让每一层都根据损失值反向调整权重；
6. Go to 2，直到精度足够好（比如损失函数值小于 0.001）。

#### 线性反向传播

代码：
import numpy as np

def target_function(w,b):  
    x = 2*w+3*b  
    y=2*b+1  
    z=x*y  
    return x,y,z  
  
def single_variable(w,b,t):  
    print("\nsingle variable: b ----- ")  
    error = 1e-5  
    while(True):  
        x,y,z = target_function(w,b)  
        delta_z = z - t  
        print("w=%f,b=%f,z=%f,delta_z=%f"%(w,b,z,delta_z))  
        if abs(delta_z) < error:  
            break  
        delta_b = delta_z /63  
        print("delta_b=%f"%delta_b)  
        b = b - delta_b  
  
    print("done!")  
    print("final b=%f"%b)  
  
def single_variable_new(w,b,t):  
    print("\nsingle variable new: b ----- ")  
    error = 1e-5  
    while(True):  
        x,y,z = target_function(w,b)  
        delta_z = z - t  
        print("w=%f,b=%f,z=%f,delta_z=%f"%(w,b,z,delta_z))  
        if abs(delta_z) < error:  
            break  
        factor_b = 2*x+3*y  
        delta_b = delta_z/factor_b  
        print("factor_b=%f, delta_b=%f"%(factor_b, delta_b))  
        b = b - delta_b  
  
    print("done!")  
    print("final b=%f"%b)  


# this version has a bug
def double_variable(w,b,t):  
    print("\ndouble variable: w, b -----")  
    error = 1e-5  
    while(True):  
        x,y,z = target_function(w,b)  
        delta_z = z - t  
        print("w=%f,b=%f,z=%f,delta_z=%f"%(w,b,z,delta_z))  
        if abs(delta_z) < error:  
            break  
        delta_b = delta_z/63/2  
        delta_w = delta_z/18/2  
        print("delta_b=%f, delta_w=%f"%(delta_b,delta_w))  
        b = b - delta_b  
        w = w - delta_w  
    print("done!")  
    print("final b=%f"%b)  
    print("final w=%f"%w)  
  
# this is correct version  
def double_variable_new(w,b,t):  
    print("\ndouble variable new: w, b -----")  
    error = 1e-5  
    while(True):  
        x,y,z = target_function(w,b)  
        delta_z = z - t  
        print("w=%f,b=%f,z=%f,delta_z=%f"%(w,b,z,delta_z))  
        if abs(delta_z) < error:  
            break  
  
        factor_b, factor_w = calculate_wb_factor(x,y)  
        delta_b = delta_z/factor_b/2  
        delta_w = delta_z/factor_w/2  
        print("factor_b=%f, factor_w=%f, delta_b=%f,   delta_w=%f"%(factor_b, factor_w, delta_b,delta_w))  
        b = b - delta_b  
        w = w - delta_w  
    print("done!")  
    print("final b=%f"%b)  
    print("final w=%f"%w)  
  
def calculate_wb_factor(x,y):  
    factor_b = 2*x+3*y  
    factor_w = 2*y  
    return factor_b, factor_w  
  
if __name__ == '__main__':  
    w = 3  
    b = 4  
    t = 150  
    single_variable(w,b,t)  
    single_variable_new(w,b,t)  
    double_variable(w,b,t)  
    double_variable_new(w,b,t)  

测试过程：

![](https://i0.hdslb.com/bfs/album/60cb39e3bd70c840e0c8e0096c10723fe4ae2c30.png@518w_1e_1c.png)

![](https://i0.hdslb.com/bfs/album/f2e2e959a0d8dcf935947e9f1e9cb321b097a936.png@518w_1e_1c.png)


#### 非线性反向传播

代码：
import numpy as np  
import matplotlib.pyplot as plt  
  
def draw_fun(X,Y):  
    x = np.linspace(1.2,10)  
    a = x*x  
    b = np.log(a)  
    c = np.sqrt(b)  
    plt.plot(x,c)  
  
    plt.plot(X,Y,'x')  
  
    d = 1/(x*np.sqrt(np.log(x**2)))  
    plt.plot(x,d)  
    plt.show()  
  
  
def forward(x):  
    a = x*x  
    b = np.log(a)  
    c = np.sqrt(b)  
    return a,b,c  
  
def backward(x,a,b,c,y):  
    loss = c - y  
    delta_c = loss  
    delta_b = delta_c * 2 * np.sqrt(b)  
    delta_a = delta_b * a  
    delta_x = delta_a / 2 / x  
    return loss, delta_x, delta_a, delta_b, delta_c  
  
def update(x, delta_x):  
    x = x - delta_x  
    if x < 1:  
        x = 1.1  
    return x  
  
if __name__ == '__main__':  
    print("how to play: 1) input x, 2) calculate c, 3) input   target number but not faraway from c")  
    print("input x as initial number(1.2,10), you can try 1.3:")    
    line = input()  
    x = float(line)  
      
    a,b,c = forward(x)  
    print("c=%f" %c)  
    print("input y as target number(0.5,2), you can try 1.8:")  
    line = input()  
    y = float(line)  
  
    error = 1e-3  
  
    X,Y = [],[]  
  
    for i in range(20):  
        # forward  
        print("forward...")  
        a,b,c = forward(x)  
        print("x=%f,a=%f,b=%f,c=%f" %(x,a,b,c))  
        X.append(x)  
        Y.append(c)  
        # backward  
        print("backward...")  
        loss, delta_x, delta_a, delta_b, delta_c = backward(x,a,b,c,y)  
        if abs(loss) < error:  
            print("done!")  
            break  
        # update x  
        x = update(x, delta_x)  
        print("delta_c=%f, delta_b=%f, delta_a=%f,   delta_x=%f\n" %(delta_c, delta_b, delta_a, delta_x))  
  
      
    draw_fun(X,Y)  

测试过程：


![](https://i0.hdslb.com/bfs/album/cba784c388496e759f963cc67e52b48007a61b07.png@518w_1e_1c.png)



#### 梯度下降

梯度下降的三要素：
1. 当前点
2. 方向
3. 步长

梯度下降包含了两层含义：
1. 梯度：函数当前位置的最快上升点
2. 下降：与导数相反的方向，用数学语言描述就是那个减号。
   
代码：
import numpy as np  
import matplotlib.pyplot as plt  
  
def target_function(x):  
    y = x*x  
    return y  
  
def derivative_function(x):  
    return 2*x  
  
def draw_function():  
    x = np.linspace(-1.2,1.2)  
    y = target_function(x)  
    plt.plot(x,y)  
  
def draw_gd(X):  
    Y = []  
    for i in range(len(X)):  
        Y.append(target_function(X[i]))  
      
    plt.plot(X,Y)  
  
if __name__ == '__main__':  
    x = 1.2  
    eta = 0.3  
    error = 1e-3  
    X = []  
    X.append(x)  
    y = target_function(x)  
    while y > error:  
        x = x - eta * derivative_function(x)  
        X.append(x)  
        y = target_function(x)  
        print("x=%f, y=%f" %(x,y))  
  
  
    draw_function()  
    draw_gd(X)  
    plt.show()  

测试过程:

![](https://i0.hdslb.com/bfs/album/45153861645128f943fcc7aab3b2a99c20803b8f.png@518w_1e_1c.png)



import numpy as np  
import matplotlib.pyplot as plt  
from mpl_toolkits.mplot3d import Axes3D  
  
def target_function(x,y):  
    J = x**2 + np.sin(y)**2  
    return J  
  
def derivative_function(theta):  
    x = theta[0]  
    y = theta[1]  
    return np.array([2*x,2*np.sin(y)*np.cos(y)])  
  
def show_3d_surface(x, y, z):  
    fig = plt.figure()  
    ax = Axes3D(fig)  
   
    u = np.linspace(-3, 3, 100)  
    v = np.linspace(-3, 3, 100)  
    X, Y = np.meshgrid(u, v)  
    R = np.zeros((len(u), len(v)))  
    for i in range(len(u)):  
        for j in range(len(v)):  
            R[i, j] = X[i, j]**2 + np.sin(Y[i, j])**2  
  
    ax.plot_surface(X, Y, R, cmap='rainbow')  
    plt.plot(x,y,z,c='black')  
    plt.show()  
  
if __name__ == '__main__':  
    theta = np.array([3,1])  
    eta = 0.1  
    error = 1e-2  
  
    X = []  
    Y = []  
    Z = []  
    for i in range(100):  
        print(theta)  
        x=theta[0]  
        y=theta[1]    
        z=target_function(x,y)  
        X.append(x)  
        Y.append(y)  
        Z.append(z)  
        print("%d: x=%f, y=%f, z=%f" %(i,x,y,z))  
        d_theta = derivative_function(theta)  
        print("    ",d_theta)  
        theta = theta - eta * d_theta  
        if z < error:  
            break  
    show_3d_surface(X,Y,Z)  

测试过程：


![](https://i0.hdslb.com/bfs/album/e39cba21f5a6f052dc81ea9a97382fcd45019073.png@518w_1e_1c.png)

import numpy as np  
import matplotlib.pyplot as plt  
  
def targetFunction(x):  
    y = (x-1)**2 + 0.1  
    return y  
  
def derivativeFun(x):  
    y = 2*(x-1)  
    return   
  
def create_sample():  
    x = np.linspace(-1,3,num=100)  
    y = targetFunction(x)  
    return x,  
  
def draw_base():  
    x,y=create_sample()  
    plt.plot(x,y,'.')  
    plt.show()  
    return x,y  
     
def gd(eta):  
    x = -0.8  
    a = np.zeros((2,10))  
    for i in range(10):  
        a[0,i] = x  
        a[1,i] = targetFunction(x)  
        dx = derivativeFun(x)  
        x = x - eta*dx  
      
    plt.plot(a[0,:],a[1,:],'x')  
    plt.plot(a[0,:],a[1,:])  
    plt.title("eta=%f" %eta)  
    plt.show()  
  
if __name__ == '__main__':  
  
    eta = [1.1,1.,0.8,0.6,0.4,0.2,0.1]  
  
    for e in eta:  
        X,Y=create_sample()  
        plt.plot(X,Y,'.')  
        #plt.show()  
        gd(e)  


测试过程：

![](https://i0.hdslb.com/bfs/album/39e7884ddac8c365115f4bdac2dc3a7a86ea5bce.png@518w_1e_1c.png)

![](https://i0.hdslb.com/bfs/album/752f94ae7f9e9d297bb69533be9c5c183d1535da.png@518w_1e_1c.png)

![](https://i0.hdslb.com/bfs/album/453c1016f35ae25c14a855936eb9af82f4d18d65.png@518w_1e_1c.png)

![](https://i0.hdslb.com/bfs/album/2b249a039e5111e6fb2bac931d032e6b8c2202a0.png@518w_1e_1c.png)

![](https://i0.hdslb.com/bfs/album/83be5ca223d7a0f3d4fd68b3385d6f82f0761c02.png@518w_1e_1c.png)

![](https://i0.hdslb.com/bfs/album/69d883e91d3ce3b978d870efcc07f3e9529290a6.png@518w_1e_1c.png)

![](https://i0.hdslb.com/bfs/album/17d9ba030a07dda35f0036dc3043e3765e413b18.png@518w_1e_1c.png)

#### 损失函数

### 概念
损失函数可以看作是误差，偏差等等，所指的意思也是和准确值之间的偏差

### 损失函数的作用

损失函数的作用是计算神经网络每次迭代的前进计算结果与事实值之间的差距，从而指导下一步的训练向正确的方向进行。
使用步骤：
1. 随机值初始化前向计算公式的参数
2. 代入样本，计算输出的预测值
3. 用损失函数计算预测值和标签值的误差
4. 根据损失函数的导数，沿着梯度最小方向将误差回传，修正前向计算公式中各个权重值
5. 重复第二步，直到损失函数达到一个满意的值就停止迭代。

代码：

import numpy as np  
import matplotlib.pyplot as plt  
  
def target_function2(a,y):  
    p1 = y * np.log(a)  
    p2 = (1-y) * np.log(1-a)  
    y = -p1 - p2  
    return y  
  
if __name__ == '__main__':  
    err = 1e-2  # avoid invalid math caculation  
    a = np.linspace(0+err,1-err)  
    y = 0  
    z1 = target_function2(a,y)  
    y = 1  
    z2 = target_function2(a,y)  
    p1, = plt.plot(a,z1)  
    p2, = plt.plot(a,z2)  
    plt.grid()  
    plt.legend([p1,p2],["y=0","y=1"])  
    plt.xlabel("a")  
    plt.ylabel("Loss")  
    plt.show()  


![](https://i0.hdslb.com/bfs/album/54987895bdcc1e57f2da2d43447754a3e2dadfc5.png@518w_1e_1c.png)

### 总结
    均方差函数，主要用于回归
    交叉熵函数，主要用于分类
    二者都是非负函数，极值在底部，用梯度下降法可以求解

### 线性回归
#### 单变量线性回归问题

回归分析是一种数学模型。当因变量和自变量为线性关系时，它是一特殊的线性模型。

最简单的情形是一元线性回归，由大体上有线性关系的一个自变量和一个因变量组成，模型是：

Y = a+bX+varepsilon

X是自变量，Y是因变量，varepsilon是随机误差，a和b是参数，在线性回归模型中，a,b是我们通过算法学习出来的。

什么叫模型？第一次接触这个概念时，可能会有些不明觉厉。从常规概念上讲，是人们通过主观意识借助实体或者虚拟表现来构成对客观事物的描述，这种描述通常是有一定的逻辑或者数学含义的抽象表达方式。

对于线性回归模型，有如下一些概念需要了解：

- 通常假定随机误差 $\varepsilon$ 的均值为 $0$，方差为$σ^2$（$σ^2>0$，$σ^2$ 与 $X$ 的值无关）
- 若进一步假定随机误差遵从正态分布，就叫做正态线性模型
- 一般地，若有 $k$ 个自变量和 $1$ 个因变量（即公式1中的 $Y$），则因变量的值分为两部分：一部分由自变量影响，即表示为它的函数，函数形式已知且含有未知参数；另一部分由其他的未考虑因素和随机性影响，即随机误差
- 当函数为参数未知的线性函数时，称为线性回归分析模型
- 当函数为参数未知的非线性函数时，称为非线性回归分析模型
- 当自变量个数大于 $1$ 时称为多元回归
- 当因变量个数大于 $1$ 时称为多重回归

使用方法：

1. 最小二乘法
2. 梯度下降法
3. 简单的神经网络法
4. 更通用的神经网络算法

#### 最小二乘法

概念：通过最小化误差的平方和寻找数据的最佳函数匹配。利用最小二乘法可以简便地求得未知的数据，并使得这些求得的数据与实际数据之间的平方和为最小。最小二乘法还可以用于曲线拟合。

设拟合曲线的公式为Y=K*X+B
拟合直线的斜率为：
K=（(X*Y)的平均值-（X的平均值*Y的平均值））/（（X*X）的平均值-（X的平均值*X的平均值））
再根据求得的（X的平均值，Y的平均值）和已经确定的斜率K，利用待定系数法求出截距B。

#### 梯度下降法

数学原理：
- 预设函数：Z=x*w+b
- 损失函数：均方差函数
  
梯度下降的原理在于梯度下降以及后面的神经网络都是利用导数传递误差，再通过迭代方式一步一步地逼近真实解。

#### 神经网络法
神经网络法，相当于在用一个最简单的单层单点神经元。
对神经元的描述，分为输入层，输入层只接受一个输入特征，经过参数w,b计算后，直接输出结果。这样一个简单的“网络”，只能解决简单的一元线性回归问题，而且由于是现行的，不需要激活函数，大大简化了程序，而且便于循序渐进地理解各种知识点。权重w,b，在一元线性问题中，w,b都是一个标量。

- 假设输出层为1个神经元，线性预测公式为：Z=X*W+B
- 损失函数使用均方差函数
- 反向传播，由于单层无激活函数的神经网络只能处理线性回归问题，因而梯度下降与反向传播的相关计算与之前的完全相同。其实神经网络法和梯度下降法在本质上是一样的，只是神经网络法使用了一个崭新的编程模式，即以神经元为中心的代码结构设计，便于后面的功能扩充。

神经元的编程模型把梯度下降法包装了一下，这样就进入了神经网络的世界，从而可以有成熟的方法论可以解决更复杂的问题，比如多个神经元协同工作、多层神经网络的协同工作等等。

#### 多样本计算

单样本计算存在的一些缺点
- 前后两个相邻的样本，很可能会对反向传播产生相反的作用而互相抵消。
- 在样本数据量大时，逐个计算会花费很长时间。

梯度下降的三种形式：
单样本随机梯度下降
小批量样本梯度下降，实际工程中通常使用
全批量样本梯度下降，受单个样本影响最小，但是数据量较大，训练过程会变慢


##### 多样本的计算中会涉及矩阵运算，而所以的深度学习框架都对矩阵运算做了优化，会大幅提升运算速度

#### 多变量线性回归

当接收多个变量输入时，成为了多变量线性回归问题。此时要通过可视化方法理解就比较困难，通常需要用变量两两组对的方式来表现。

当变量多于一个时，两个变量的量纲和数值有可能差别很大，这种情况下，我们通常需要对样本特征数据做归一化，然后把数据喂给神经网络进行训练，否则会出现“消化不良”的情况。

#### 多元线性回归模型
- 多元线性回归模型
     Y=A0+A1*X1+A2*X2+...+AK*XK
- 对于一般的应用问题，建立多元线性回归模型时，为了保证回归模型具有优良的解释能力和预测效果，首先需要注意自变量的选择，其准则是：
  
  自变量对因变量必须有显著的影响，并呈密切的线性相关；
  自变量与因变量之间的线性相关必须是真实的，而不是形式上的；
  自变量之间应具有一定的互斥性，即自变量之间的相关程度不应高于自变量与因变量之因的相关程度；
  自变量应具有完整的统计数据，其预测值容易确定

  对于线性回归问题，求解方法可以用传统的数学方法解决这个问题，使用正规方程法，从而得到数学解析解；再使用神经网络方式来求得近似解，从而比较两者的精度，再进一步调试神经网络的参数，打到学习的目的。

- 数据标准化：深度学习的必要步骤之一，已经是大师们的必杀技能。理论层面上，神经网络是以样本在事件中的统计分布概率为基础进行训练和预测的，所以它对于样本数据的要求比较苛刻。
  
- 还原参数值：超参修改，还原真实的W,B值，唯一可以修改的地方就是样本数据特征值的标准化，并没有修改标签值。

- 标签值标准化：预测数据的标准化，只需要把训练数据的最小值和最大值记录下来，在预测时使用它们对预测数据做标准化，就相当于把预测数据“混入”训练数据。代码运行结果与正规方程解非常接近。我们只需要把预测数据看作是训练数据的一个记录，先标准化，再做预测，这样就不需要把权重矩阵还原了。
  
#### 线性二分类

分类问题在很多资料中都称为逻辑回归，其原因就是使用了线性模型加一个LOGISTIC二分类函数，共同构成了这样的分类器。神经网络的一个重要功能就是分类，现实世界中的分类任务复杂多样，但万变不离其宗，可以用同一种模式的神经网络来处理。

逻辑回归模型，逻辑回归是用来计算“事件=Success”和事件“Failure”的概率。当因变量的类型属于二元变量时，我们应该使用逻辑回归。

回忆线性回归，使用一条直线拟合样本数据，而逻辑回归是“拟合”0或1两个数值，而不是具体的连续数值，所以它叫广义线性模型。逻辑回归又称Logistic回归分析，常用于数据挖掘，疾病自动诊断，经济预测等领域。

逻辑回归的另一个名字叫做分类器，分为线性分类器和非线性分类器。

对率函数：既可以做激活函数使用，又可以当作二分类函数使用。在分类任务中，称其为Logistic函数，而作为激活函数时，称其为Sigmoid函数。它的定义域为全体实数，值域为（0，1）

#### 线性多分类

做多分类任务时，可以采用一对一，一对多，多对多的方式，那么神经网络使用的是哪一种方式，是需要思考的问题，SOFTMAX函数是多分类问题的分类函数，通过对它的分析，我们进一步学习多分类的原理，实现，以及可视化结果，从而理解神经网络的工作方式。

多分类的学习策略，线性多分类和非线性多分类的结果比较，直观的看，区别在于不同类别的样本点之间是否可以用一条直线来相互分割。线性多分类可以使用单层结构来解决，而非线性多分类需要使用双层结构。

多分类问题的三种解法
一对一方式:每次先只保留两个类别的数据，训练一个分类器。如果数据有N类，则需要训练C2n个分类器。
一对多方式：处理一个类别时，暂时把其他所有类别看作是一类。
多对多方式：多个类别数据组合，作二分类，预测时结合多个分类结果进行逻辑运算。

多标签学习
- 同时被标注多个标签，区别于多分类问题。

SOFTMAX函数
假设输入值时[3,1,-3],如果直接取MAX操作会变成[1,0,0],符合分类需要，有两个不足：
        分类结果缺少各元素间相差多少的信息，可以理解为“HARD-MAX”
        MAX函数本身不可导，无法应用于反向传播
    所以SOFTMAX函数加了个“SOFT”来模拟MAX的行为，同时保留了相对大小的信息

SOFT函数的特点
- 各个类别概率相加和为1
- 各个类别的概率均为非负

## 非线性回归
### 激活函数
### 激活函数的概论
### 激活函数的基本作用

图8-1是神经网络中的一个神经元，假设该神经元有三个输入，分别为$x_1,x_2,x_3$，那么：

$$z=x_1 w_1 + x_2 w_2 + x_3 w_3 +b \tag{1}$$
$$a = \sigma(z) \tag{2}$$

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/1/NeuranCell.png" width="500" />

图8-1 激活函数在神经元中的位置

激活函数的作用：
1.给神经网络增加非线性因素。
2.把公式1的计算结果压缩到$[0,1]$ 之间。

激活函数的基本性质：
+ 非线性：线性的激活函数和没有激活函数一样；
+ 可导性：做误差反向传播和梯度下降，必须要保证激活函数的可导性；
+ 单调性：单一的输入会得到单一的输出，较大值的输入得到较大值的输出。

### 激活函数的时间

激活函数是用在神经网络的层与层之间的连接，神经网络的最后一层不用激活。神经网络不管有多少层，最后的输出层决定了这个神经网络能干什么。

单层的神经网络的参数与功能

|网络|输入|输出|激活函数|分类函数|功能|
|---|---|---|---|---|---|
|单层|单变量|单输出|无|无|线性回归|
|单层|多变量|单输出|无|无|线性回归|
|单层|多变量|单输出|无|二分类函数|二分类|
|单层|多变量|多输出|无|多分类函数|多分类|

从这里可以知道：
1.神经网络最后一层不需要激活函数
2.激活函数只用于连接前后两层神经网络

### 挤压型激活函数

这一类函数的特点是，当输入值域的绝对值较大的时候，其输出在两端是饱和的，都具有S形的函数曲线以及压缩输入值域的作用，所以叫挤压型激活函数，又可以叫饱和型激活函数。

在神经网络中，有两个常用的Sigmoid函数，一个是Logistic函数，另一个Tanh函数。

### Logistic函数

Logistic函数即为对数w几率函数。

公式

$$Sigmoid(z) = \frac{1}{1 + e^{-z}} \rightarrow a \tag{1}$$

导数

$$Sigmoid'(z) = a(1 - a) \tag{2}$$

推导过程如下：
令：$u=1,v=1+e^{-z}$ 则：
$$
\begin{aligned}
Sigmoid'(z)&= (\frac{u}{v})'=\frac{u'v-v'u}{v^2} \\\\
&=\frac{0-(1+e^{-z})'}{(1+e^{-z})^2}=\frac{e^{-z}}{(1+e^{-z})^2} \\\\
&=\frac{1+e^{-z}-1}{(1+e^{-z})^2}=\frac{1}{1+e^{-z}}-(\frac{1}{1+e^{-z}})^2 \\\\
&=a-a^2=a(1-a)
\end{aligned}
$$

值域
- 输入值域：$(-\infty, \infty)$
- 输出值域：$(0,1)$
- 导数值域：$(0,0.25]$

#### 函数图像

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/8/sigmoid.png" ch="500" />

图8-3 Sigmoid函数图像

#### 优点

从数学上来看，Sigmoid函数对中央区的信号增益较大，对两侧区的信号增益小，在信号的特征空间映射上，有很好的效果。
从神经科学上来看，中央区酷似神经元的兴奋态，两侧区酷似神经元的抑制态，因而在神经网络学习方面，可以将重点特征推向中央区，将非重点特征推向两侧区。

#### 缺点

指数计算代价大。

### Tanh函数
TanHyperbolic，即双曲正切函数。

### 公式
$$Tanh(z) = \frac{e^{z} - e^{-z}}{e^{z} + e^{-z}} = (\frac{2}{1 + e^{-2z}}-1) \rightarrow a \tag{3}$$
即
$$Tanh(z) = 2 \cdot Sigmoid(2z) - 1 \tag{4}$$

### 导数公式

$$Tanh'(z) = (1 + a)(1 - a)$$

利用基本导数公式23，令：$u={e^{z}-e^{-z}}，v=e^{z}+e^{-z}$ 则有：
$$
\begin{aligned}
Tanh'(z)&=\frac{u'v-v'u}{v^2} \\\\
&=\frac{(e^{z}-e^{-z})'(e^{z}+e^{-z})-(e^{z}+e^{-z})'(e^{z}-e^{-z})}{(e^{z}+e^{-z})^2} \\\\
&=\frac{(e^{z}+e^{-z})(e^{z}+e^{-z})-(e^{z}-e^{-z})(e^{z}-e^ {-z})}{(e^{z}+e^{-z})^2} \\\\
&=\frac{(e^{z}+e^{-z})^2-(e^{z}-e^{-z})^2}{(e^{z}+e^{-z})^2} \\\\
&=1-(\frac{(e^{z}-e^{-z}}{e^{z}+e^{-z}})^2=1-a^2
\end{aligned}
$$

### 值域

- 输入值域：$(-\infty,\infty)$
- 输出值域：$(-1,1)$
- 导数值域：$(0,1)$

### 函数图像

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/8/tanh.png" ch="500" />

### 优点
具有Sigmoid的所有优点
同时在传递过程中，输入数据的均值并不会发生改变，这就使他在很多应用中能表现出比Sigmoid优异一些的效果。

### 缺点
exp指数计算代价大。梯度消失问题仍然存在。

### 代码测试



### 半线性激活函数

### ReLU函数

修正线性单元，线性整流函数，斜坡函数。

### 公式
$$ReLU(z) = max(0,z) = \begin{cases} 
  z, & z \geq 0 \\\\ 
  0, & z < 0 
\end{cases}$$

### 导数
$$ReLU'(z) = \begin{cases} 1 & z \geq 0 \\\\ 0 & z < 0 \end{cases}$$

### 值域
- 输入值域：$(-\infty, \infty)$
- 输出值域：$(0,\infty)$
- 导数值域：$\\{0,1\\}$

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/8/relu.png"/>

### 优点

- 反向导数恒等于1，更加有效率的反向传播梯度值，收敛速度快；
- 避免梯度消失问题；
- 计算简单，速度快；
- 活跃度的分散性使得神经网络的整体计算成本下降。

### 缺点
无界。

### 8.2.2 Leaky ReLU函数
LReLU，带泄露的线性整流函数。

### 公式
$$LReLU(z) = \begin{cases} z & z \geq 0 \\\\ \alpha \cdot z & z < 0 \end{cases}$$

### 导数
$$LReLU'(z) = \begin{cases} 1 & z \geq 0 \\\\ \alpha & z < 0 \end{cases}$$

### 值域
输入值域：$(-\infty, \infty)$
输出值域：$(-\infty,\infty)$
导数值域：$\\{\alpha,1\\}$

### 函数图像

函数图像如图所示。
<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/8/leakyRelu.png"/>

### 优点
继承了ReLU函数的优点，具有收敛快速和运算复杂度低的优点。

### Softplus函数
### 公式
$$Softplus(z) = \ln (1 + e^z)$$

### 导数
$$Softplus'(z) = \frac{e^z}{1 + e^z}$$

### 
输入值域：$(-\infty, \infty)$
输出值域：$(0,\infty)$
导数值域：$(0,1)$

### 函数图像

Softplus的函数图像如图8-8所示。
<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/8/softplus.png"/>

### 8.2.4 ELU函数

#### 公式
$$ELU(z) = \begin{cases} z & z \geq 0 \\ \alpha (e^z-1) & z < 0 \end{cases}$$

#### 导数
$$ELU'(z) = \begin{cases} 1 & z \geq 0 \\ \alpha e^z & z < 0 \end{cases}$$

#### 值域
输入值域：$(-\infty, \infty)$
输出值域：$(-\alpha,\infty)$
导数值域：$(0,1]$

#### 函数图像
ELU的函数图像如图8-9所示。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/8/elu.png"/>

### 单入单出的双层神经网络-非线性回归

### 思考：
在思考解决非线性回归的问题时，首先可以明确自变量X和因变量Y之间不是线性关系。常用的传统的处理方法有线性迭代法、分段回归法、迭代最小二乘法等。在解决这一类问题中，我们需要思考一个隐层的两层神经网络。

### 回归模型的评价标准

回归问题主要是求值，评价标准主要是看求得值与实际结果的偏差有多大，所以，回归问题主要以下方法来评价模型。

### 用多项式回归法拟合正弦曲线

### 多项式回归的概念

多项式回归有几种形式：
一元一次线性模型、多元一次多项式、一元多次多项式、多元多次多项式

### 双层神经网络实现非线性回归

### 万能近似定理

万能近似定理(universal approximation theorem) $^{[1]}$，是深度学习最根本的理论依据。它证明了在给定网络具有足够多的隐藏单元的条件下，配备一个线性输出层和一个带有任何“挤压”性质的激活函数（如Sigmoid激活函数）的隐藏层的前馈神经网络，能够以任何想要的误差量近似任何从一个有限维度的空间映射到另一个有限维度空间的Borel可测的函数。

前馈网络的导数也可以以任意好地程度近似函数的导数。

### 定义神经网络结构

本节的目的是要用神经网络完成图9-1和图9-2中的曲线拟合。

根据万能近似定理的要求，我们定义一个两层的神经网络，输入层不算，一个隐藏层，含3个神经元，一个输出层。图9-7显示了此次用到的神经网络结构。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/9/nn.png" />

图9-7 单入单出的双层神经网络

### 曲线拟合

### 正弦曲线的拟合
### 隐层只有一个神经元的情况

令`n_hidden=1`，并指定模型名称为`sin_111`，训练过程见图9-10。图9-11为拟合效果图。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/9/sin_loss_1n.png" />

训练过程中损失函数值和准确率的变化

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/9/sin_result_1n.png" ch="500" />

一个神经元的拟合效果

损失值到0.04附近就很难下降了。

### 非线性回归的工作原理
### 多项式为何能拟合曲线
使用多项式回归法，它成功地用于正弦曲线和复合函数曲线的拟合，其基本工作原理是把单一特征值的高次方做为额外的特征值加入，使得神经网络可以得到附加的信息用于训练。

观察多项式回归的示意图

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/9/polynomial_concept.png"/>
多项式回归方法的特征值输入

单层神经网络的多项式回归法，需要$x,x^2,x^3$三个特征值，组成如下公式来得到拟合结果：

$$
z = x \cdot w_1 + x^2 \cdot w_2 + x^3 \cdot w_3 + b \tag{1}
$$

第一步 把X拆成两个线性序列z1和z2

假设原始值x有21个点，样本数据如表9-15所示。

表9-15

|id|0|1|2|...|19|20|21|
|--|--|--|--|--|--|--|--|
|x|0.|0.05|0.1|...|0.9|0.95|1.|

通过以下线性变换，被分成了两个线性序列，得到下表所示的隐层值：

$$
z1 = x \cdot w_{11} + b_{11} \tag{2}
$$
$$
z2 = x \cdot w_{12} + b_{12} \tag{3}
$$

其中：

- $w_{11} = -2.673$
- $b_{11} = 1.303$
- $w_{12} = -9.036$
- $b_{12} = 4.507$

隐层线性变化结果

||0|1|2|...|19|20|21|
|--|--|--|--|--|--|--|--|
|z1|1.303|1.169|1.035|...|-1.102|-1.236|-1.369|
|z2|4.507|4.055|3.603|...|-3.625|-4.077|-4.528|

三个线性序列如图9-19所示，黑色点是原始数据序列，红色和绿色点是拆分后的两个序列。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/9/nn_concept_x_z1_z2.png" ch="500" />

从原始数据序列拆分成的两个数据序列

这个运算相当于把特征值分解成两个部分，不太容易理解。打个不太恰当的比喻，有一个浮点数12.34，你可以把它拆成12和0.34两个部分，然后去分别做一些运算。另外一个例子就是，一张彩色图片上的黄色，我们普通人看到的就是黄色，但是画家会想到是红色和绿色的组合。

第二步 计算z1的激活函数值a1

下表和下图分别展示了隐层对第一个特征值的计算结果数值和示意图。

第一个特征值及其激活函数结果数值

||0|1|2|...|19|20|21|
|--|--|--|--|--|--|--|--|
|z1|1.303|1.169|1.035|...|-1.102|-1.236|-1.369|
|a1|0.786|0.763|0.738|...|0.249|0.225|0.203|

第二行的a1值等于第1行的z1值的sigmoid函数值：

$$a1 = {1 \over 1+e^{-z1}} \tag{4}$$

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/9/nn_concept_x_z1_a1.png" ch="500" />

第一个特征值及其激活函数结果可视化

z1还是一条直线，但是经过激活函数后的a1已经不是一条直线了。上面这张图由于z1的跨度大，所以a1的曲线程度不容易看出来。

第三步 计算z2的激活函数值a2

下表和下图分别展示了隐层对第二个特征值的计算结果数值和示意图。

第二个特征值及其激活函数结果数值

||0|1|2|...|19|20|21|
|--|--|--|--|--|--|--|--|
|z2|4.507|4.055|3.603|...|-3.625|-4.077|-4.528|
|a2|0.989|0.983|0.973|...|0.026|0.017|0.011|

$$a2 = {1 \over 1+e^{-z2}} \tag{5}$$

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/9/nn_concept_x_z2_a2.png" ch="500" />

第二个特征值及其激活函数结果可视化

z2还是一条直线，但是经过激活函数后的a2已经明显看出是一条曲线了。

第四步 计算Z值

下表和下图分别展示了输出层对两个特征值的计算结果数值和示意图。

输出层的计算结果数值

||0|1|2|...|19|20|21|
|--|--|--|--|--|--|--|--|
|a1|0.786|0.763|0.738|...|0.249|0.225|0.203|
|a2|0.989|0.983|0.973|...|0.026|0.017|0.011|
|z|0.202|0.383|0.561|...|-0.580|-0.409|-0.235|

$$z = a1 \cdot w_{11} + a2 \cdot w_{21} + b \tag{6}$$

其中：

- $w_{11}=-9.374$
- $w_{21}=6.039$
- $b=1.599$
  
<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/9/nn_concept_a1_a2_z.png" ch="500" />

输出层的计算结果可视化

也就是说，相同x值的红点a1和绿点a2，经过公式6计算后得到蓝点z，而所有的蓝点就拟合出一条正弦曲线。

比较多项式回归和双层神经网络解法


多项式回归和神经网络的比较

||多项式回归|双层神经网络|
|---|---|---|
|特征提取方式|特征值的高次方|线性变换拆分|
|特征值数量级|高几倍的数量级|数量级与原特征值相同|
|训练效率|低，需要迭代次数多|高，比前者少好几个数量级|

### 总结
-综上可知多项式回归在各个方面均处于绝对的优势地位。

### 超参数优化的初步认识

通过学习可以得知在超参数优化中主要存在两方面的困难：

1.超参数优化是一个组合优化问题，无法无法像一般参数那样通过梯度下降方法来优化，也没有一种通用有效的优化方法。
2.评估一组超参数配置的时间代价很高，导致一些优化方法在超参数优化难以应用。

对于超参数的设置，比较简单的方法是人工搜索、网络搜索和随机搜索。

其中最终可以调整的参数只有三个：
- 隐层神经元数
- 学习率
- 批样本量

在使用中我们还需要做到避免权重矩阵初始化的影响

权重矩阵中的参数，是神经网络要学习的参数，所以不能称作超参数。

权重矩阵初始化是神经网络训练非常重要的环节之一，不同的初始化方法，甚至是相同的方法但不同的随机值，都会给结果带来或多或少的影响。

在进行手动调整参数时，我们还必须了解超参数、训练误差、泛化误差和计算资源之间的相应关系。

# step4 总结

通过对双层神经网络的学习，学习了如何解决非线性问题。在两层神经网络之间，需要有激活函数的连接，从而提升神经网络的能力。通过单入淡出双层的非线性回归，分析了多项式回归法拟合正弦曲线和多项式回归法拟合复合函数曲线，同时进行了验证和测试，在神经网络非线性回归实现中，学习了万能近似定理，对其的可实现性进行了全面分析，分析了其实现中对其产生影响的因素，进行了论证，同时分析了使用曲线拟合的各各方面，了解了非线性回归的工作原理，最后学习了参数调优初步的使用。

## 10 非线性分类

### 10.0-多入单出双层-非线性二分类

二分类模型的评估标准
精确度也被称之为精度

混淆矩阵分成4部分来评估：

- 正例中被判断为正类的样本数（TP-True Positive）：521
- 正例中被判断为负类的样本数（FN-False Negative）：550-521=29
- 负例中被判断为负类的样本数（TN-True Negative）：435
- 负例中被判断为正类的样本数（FP-False Positive）：450-435=15

可以用下图来帮助理解。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/10/TPFP.png"/>

用表格的方式描述矩阵的话是下表的样子。

四类样本的矩阵关系

|预测值|被判断为正类|被判断为负类|Total|
|---|---|---|---|
|样本实际为正例|TP-True Positive|FN-False Negative|Actual Positive=TP+FN|
|样本实际为负例|FP-False Positive|TN-True Negative|Actual Negative=FP+TN|
|Total|Predicated Postivie=TP+FP|Predicated Negative=FN+TN|

>准确率，越大越好。<br>
>分子为被判断为正类并且真的是正类的样本数，分母是被判断为正类的样本数。越大越好。<br>
>分子为被判断为正类并且真的是正类的样本数，分母是真的正类的样本数。越大越好。<br>
>分子为被判断为正类的负例样本数，分母为所有负类样本数。越小越好。<br>
>调和平均值越大越好

### 10.2 非线性二分类实现

定义完成非线性二分类的神经网络结构图，下图所示

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/10/xor_nn.png" />

- 输入层两个特征值$x_1,x_2$
  $$
  X=\begin{pmatrix}
    x_1 & x_2
  \end{pmatrix}
  $$

- 隐层$2\times 2$的权重矩阵$W1$
$$
  W1=\begin{pmatrix}
    w1_{11} & w1_{12} \\\\
    w1_{21} & w1_{22} 
  \end{pmatrix}
$$
- 隐层$1\times 2$的偏移矩阵$B1$

$$
  B1=\begin{pmatrix}
    b1_{1} & b1_{2}
  \end{pmatrix}
$$

- 隐层由两个神经元构成
$$
Z1=\begin{pmatrix}
  z1_{1} & z1_{2}
\end{pmatrix}
$$

$$
A1=\begin{pmatrix}
  a1_{1} & a1_{2}
\end{pmatrix}
$$

- 输出层$1\times 1$的偏移矩阵$B2$

$$
  B2=\begin{pmatrix}
    b2_{1}
  \end{pmatrix}
$$

- 输出层有一个神经元使用Logistic函数进行分类
$$
  Z2=\begin{pmatrix}
    z2_{1}
  \end{pmatrix}
$$
$$
  A2=\begin{pmatrix}
    a2_{1}
  \end{pmatrix}
$$

### 10.3 实现逻辑异或门

运行结果

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/10/xor_loss.png" />

### 10.4 逻辑异或门的工作原理

运行结果
<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/10/xor_result_2d.png" ch="500" />

### 10.5 实现双弧形二分类

运行结果
<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/10/sin_loss.png" />


## 10.6 双弧形二分类的工作原理

运行结果

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/10/sin_data_source.png" ch="500" />

# 第11章 多入多出的双层神经网络 - 非线性多分类

## 11.0 非线性多分类问题

### 11.0.1 提出问题：铜钱孔形问题

多分类问题数据样本
非线性多分类

|样本|$x_1$|$x_2$|$y$|
|---|---|---|---|
|1|0.22825111|-0.34587097|2|
|2|0.20982606|0.43388447|3|
|...|...|...|...|
|1000|0.38230143|-0.16455377|2|

还好这个数据只有两个特征，所以我们可以用可视化的方法展示，如图

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/11/data.png" ch="500" />

可视化样本数据

一共有3个类别：

1. 蓝色方点
2. 红色叉点
3. 绿色圆点

### 11.1 非线性多分类

非线性多分类的神经网络结构图
<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/11/nn.png" />

### 11.2 非线性多分类的工作原理

运行结果
|||
|---|---|
|<img src='../Images/11/multiple_3d_c1_1.png'/>|<img src='../Images/11/multiple_3d_c2_1.png'/>|
|红色：类别1样本区域|红色：类别2样本区域|
|<img src='../Images/11/multiple_3d_c3_1.png'/>|<img src='../Images/11/multiple_3d_c1_c2_1.png'/>|

### 12.0 多变量非线性多分类

学习率与批大小是对梯度下降影响最大的两个因子。 

梯度下降公式： $$ w_{t+1} = w_t - \frac{\eta}{m} \sum_i^m \nabla J(w,b) $$

其中:

1.$\eta$：学习率.
1.m：批大小。

## 深度神经网络
### 第14章 搭建深度神经网络框架
### 14.0深度神经网络框架设计

下图是迷你框架的模块化设计，下面对各个模块做功能点上的解释。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/class.png" />


#### NeuralNet

首先需要一个`NeuralNet`类，来包装基本的神经网络结构和功能：

- `Layers` - 神经网络各层的容器，按添加顺序维护一个列表
- `Parameters` - 基本参数，包括普通参数和超参
- `Loss Function` - 提供计算损失函数值，存储历史记录并最后绘图的功能
- `LayerManagement()` - 添加神经网络层
- `ForwardCalculation()` - 调用各层的前向计算方法
- `BackPropagation()` - 调用各层的反向传播方法
- `PreUpdateWeights()` - 预更新各层的权重参数
- `UpdateWeights()` - 更新各层的权重参数
- `Train()` - 训练
- `SaveWeights()` - 保存各层的权重参数
- `LoadWeights()` - 加载各层的权重参数

#### Layer

是一个抽象类，以及更加需要增加的实际类，包括：

- Fully Connected Layer
- Classification Layer
- Activator Layer
- Dropout Layer
- Batch Norm Layer

将来还会包括：

- Convolution Layer
- Max Pool Layer

每个Layer都包括以下基本方法：
 - `ForwardCalculation()` - 调用本层的前向计算方法
 - `BackPropagation()` - 调用本层的反向传播方法
 - `PreUpdateWeights()` - 预更新本层的权重参数
 - `UpdateWeights()` - 更新本层的权重参数
 - `SaveWeights()` - 保存本层的权重参数
 - `LoadWeights()` - 加载本层的权重参数

#### Activator Layer

激活函数和分类函数：

- `Identity` - 直传函数，即没有激活处理
- `Sigmoid`
- `Tanh`
- `Relu`

#### Classification Layer

分类函数，包括：

- `Sigmoid`二分类
- `Softmax`多分类


 #### Parameters

 基本神经网络运行参数：

 - 学习率
 - 最大`epoch`
 - `batch size`
 - 损失函数定义
 - 初始化方法
 - 优化器类型
 - 停止条件
 - 正则类型和条件

#### LossFunction

损失函数及帮助方法：

- 均方差函数
- 交叉熵函数二分类
- 交叉熵函数多分类
- 记录损失函数
- 显示损失函数历史记录
- 获得最小函数值时的权重参数

#### Optimizer

优化器：

- `SGD`
- `Momentum`
- `Nag`
- `AdaGrad`
- `AdaDelta`
- `RMSProp`
- `Adam`

#### WeightsBias

权重矩阵，仅供全连接层使用：

- 初始化 
  - `Zero`, `Normal`, `MSRA` (`HE`), `Xavier`
  - 保存初始化值
  - 加载初始化值
- `Pre_Update` - 预更新
- `Update` - 更新
- `Save` - 保存训练结果值
- `Load` - 加载训练结果值

#### DataReader

样本数据读取器：

- `ReadData` - 从文件中读取数据
- `NormalizeX` - 归一化样本值
- `NormalizeY` - 归一化标签值
- `GetBatchSamples` - 获得批数据
- `ToOneHot` - 标签值变成OneHot编码用于多分类
- `ToZeroOne` - 标签值变成0/1编码用于二分类
- `Shuffle` - 打乱样本顺序

从中派生出两个数据读取器：

- `MnistImageDataReader` - 读取MNIST数据
- `CifarImageReader` - 读取Cifar10数据

### 14.1 回归任务功能测试

模型很简单，一个双层的神经网络，第一层后面接一个Sigmoid激活函数，第二层直接输出拟合数据，如图

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/ch09_net.png" />

```Python
def model():
    dataReader = LoadData()
    num_input = 1
    num_hidden1 = 4
    num_output = 1

    max_epoch = 10000
    batch_size = 10
    learning_rate = 0.5

    params = HyperParameters_4_0(
        learning_rate, max_epoch, batch_size,
        net_type=NetType.Fitting,
        init_method=InitialMethod.Xavier,
        stopper=Stopper(StopCondition.StopLoss, 0.001))

    net = NeuralNet_4_0(params, "Level1_CurveFittingNet")
    fc1 = FcLayer_1_0(num_input, num_hidden1, params)
    net.add_layer(fc1, "fc1")
    sigmoid1 = ActivationLayer(Sigmoid())
    net.add_layer(sigmoid1, "sigmoid1")
    fc2 = FcLayer_1_0(num_hidden1, num_output, params)
    net.add_layer(fc2, "fc2")

    net.train(dataReader, checkpoint=100, need_test=True)

    net.ShowLossHistory()
    ShowResult(net, dataReader)
```

超参数说明：

1. 输入层1个神经元，因为只有一个`x`值
2. 隐层4个神经元，对于此问题来说应该是足够了，因为特征很少
3. 输出层1个神经元，因为是拟合任务
4. 学习率=0.5
5. 最大`epoch=10000`轮
6. 批量样本数=10
7. 拟合网络类型
8. Xavier初始化
9. 绝对损失停止条件=0.001

训练结果如下：

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/ch09_loss.png" />

拟合结果如下：

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/ch09_result.png" />

### 14.2 回归任务 - 房价预测

### 数据

数据集来自：https://www.kaggle.com/harlfoxem/housesalesprediction

此数据集是King County地区2014年五月至2015年五月的房屋销售信息，适合于训练回归模型。

### 数据字段解读

- id：唯一id
- date：售出日期
- price：售出价格（标签值）
- bedrooms：卧室数量
- bathrooms：浴室数量
- sqft_living：居住面积
- sqft_lot：停车场面积
- floors：楼层数
- waterfront：泳池
- view：有多少次看房记录
- condition：房屋状况
- grade：评级
- sqft_above：地面上的面积
- sqft_basement：地下室的面积
- yr_built：建筑年份
- yr_renovated：翻修年份
- zipcode：邮政编码
- lat：维度
- long：经度
- sqft_living15：2015年翻修后的居住面积
- sqft_lot15：2015年翻修后的停车场面积

### 搭建模型

构建一个模型，这个模型包含了四组全连接层-Relu层的组合，最后是一个单输出做拟合。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/non_linear_regression.png" />

```Python
def model():
    dr = LoadData()

    num_input = dr.num_feature
    num_hidden1 = 32
    num_hidden2 = 16
    num_hidden3 = 8
    num_hidden4 = 4
    num_output = 1

    max_epoch = 1000
    batch_size = 16
    learning_rate = 0.1

    params = HyperParameters_4_0(
        learning_rate, max_epoch, batch_size,
        net_type=NetType.Fitting,
        init_method=InitialMethod.Xavier,
        stopper=Stopper(StopCondition.StopDiff, 1e-7))

    net = NeuralNet_4_0(params, "HouseSingle")

    fc1 = FcLayer_1_0(num_input, num_hidden1, params)
    net.add_layer(fc1, "fc1")
    r1 = ActivationLayer(Relu())
    net.add_layer(r1, "r1")
    ......
    fc5 = FcLayer_1_0(num_hidden4, num_output, params)
    net.add_layer(fc5, "fc5")

    net.train(dr, checkpoint=10, need_test=True)
    
    output = net.inference(dr.XTest)
    real_output = dr.DeNormalizeY(output)
    mse = np.sum((dr.YTestRaw - real_output)**2)/dr.YTest.shape[0]/10000
    print("mse=", mse)
    
    net.ShowLossHistory()

    ShowResult(net, dr)
```
超参数说明：

1. 学习率=0.1
2. 最大`epoch=1000`
3. 批大小=16
4. 拟合网络
5. 初始化方法Xavier
6. 停止条件为相对误差`1e-7`

训练结果：

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/house_loss.png" />

### 14.3二分类任务功能测试

搭建模型

双层神经网络，最后一层接一个Logistic二分类函数来完成二分类任务

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/ch10_net.png" />

```Python

def model(dataReader):
    num_input = 2
    num_hidden = 3
    num_output = 1

    max_epoch = 1000
    batch_size = 5
    learning_rate = 0.1

    params = HyperParameters_4_0(
        learning_rate, max_epoch, batch_size,
        net_type=NetType.BinaryClassifier,
        init_method=InitialMethod.Xavier,
        stopper=Stopper(StopCondition.StopLoss, 0.02))

    net = NeuralNet_4_0(params, "Arc")

    fc1 = FcLayer_1_0(num_input, num_hidden, params)
    net.add_layer(fc1, "fc1")
    sigmoid1 = ActivationLayer(Sigmoid())
    net.add_layer(sigmoid1, "sigmoid1")
    
    fc2 = FcLayer_1_0(num_hidden, num_output, params)
    net.add_layer(fc2, "fc2")
    logistic = ClassificationLayer(Logistic())
    net.add_layer(logistic, "logistic")

    net.train(dataReader, checkpoint=10, need_test=True)
    return net
```
超参数说明：

1. 输入层神经元数为2
2. 隐层的神经元数为3，使用Sigmoid激活函数
3. 由于是二分类任务，所以输出层只有一个神经元，用Logistic做二分类函数
4. 最多训练1000轮
5. 批大小=5
6. 学习率=0.1
7. 绝对误差停止条件=0.02

运行结果：

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/ch10_loss.png" />

### 14.4 二分类任务真实案例

准备数据：

此数据集是从1994 Census数据库中提取

数据字段解读

标签值：>50K，<=50K。

属性字段：

- `age`，年龄：连续值
- `workclass`，工作性质：枚举型，类似私企、政府之类的
- `fnlwgt`，权重：连续值
- `education`，教育程度：枚举型，如学士、硕士等
- `education-num`，受教育的时长：连续值
- `marital-status`，婚姻状况：枚举型，已婚、未婚、离异等
- `occupation`，职业：枚举型，包含的种类很多，如技术支持、维修工、销售、农民渔民、军人等
- `relationship`，家庭角色：枚举型，丈夫、妻子等
- `sex`，性别：枚举型
- `capital-gain`，资本收益：连续值
- `capitial-loss`，资本损失：连续值
- `hours-per-week`，每周工作时长：连续值
- `native-country`，祖籍：枚举型

数据处理

数据分析和数据处理实际上是一门独立的课，超出类本书的范围，所以我们只做一些简单的数据处理，以便神经网络可以用之训练。

加载数据

```Python
train_file = "../../Data/ch14.Income.train.npz"
test_file = "../../Data/ch14.Income.test.npz"

def LoadData():
    dr = DataReader_2_0(train_file, test_file)
    dr.ReadData()
    dr.NormalizeX()
    dr.Shuffle()
    dr.GenerateValidationSet()
    return dr
```

搭建模型

为了完成二分类任务，在最后接一个Logistic函数

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/income_net.png" />

```Python
def model(dr):
    num_input = dr.num_feature
    num_hidden1 = 32
    num_hidden2 = 16
    num_hidden3 = 8
    num_hidden4 = 4
    num_output = 1

    max_epoch = 100
    batch_size = 16
    learning_rate = 0.1

    params = HyperParameters_4_0(
        learning_rate, max_epoch, batch_size,
        net_type=NetType.BinaryClassifier,
        init_method=InitialMethod.MSRA,
        stopper=Stopper(StopCondition.StopDiff, 1e-3))

    net = NeuralNet_4_0(params, "Income")

    fc1 = FcLayer_1_0(num_input, num_hidden1, params)
    net.add_layer(fc1, "fc1")
    a1 = ActivationLayer(Relu())
    net.add_layer(a1, "relu1")
    ......
    fc5 = FcLayer_1_0(num_hidden4, num_output, params)
    net.add_layer(fc5, "fc5")
    logistic = ClassificationLayer(Logistic())
    net.add_layer(logistic, "logistic")

    net.train(dr, checkpoint=1, need_test=True)
    return net
```

超参数说明：

1. 学习率=0.1
2. 最大`epoch=100`
3. 批大小=16
4. 二分类网络类型
5. MSRA初始化
6. 相对误差停止条件1e-3

训练结果

训练过程中损失函数值和精确率的变化

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/income_loss.png" />

### 多分类功能测试

搭建模型一

使用Sigmoid做为激活函数的两层网络

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/ch11_net_sigmoid.png" />

代码

```Python
def model_sigmoid(num_input, num_hidden, num_output, hp):
    net = NeuralNet_4_0(hp, "chinabank_sigmoid")

    fc1 = FcLayer_1_0(num_input, num_hidden, hp)
    net.add_layer(fc1, "fc1")
    s1 = ActivationLayer(Sigmoid())
    net.add_layer(s1, "Sigmoid1")

    fc2 = FcLayer_1_0(num_hidden, num_output, hp)
    net.add_layer(fc2, "fc2")
    softmax1 = ClassificationLayer(Softmax())
    net.add_layer(softmax1, "softmax1")

    net.train(dataReader, checkpoint=50, need_test=True)
    net.ShowLossHistory()
    
    ShowResult(net, hp.toString())
    ShowData(dataReader)
```

超参数说明

1. 隐层8个神经元
2. 最大`epoch=5000`
3. 批大小=10
4. 学习率0.1
5. 绝对误差停止条件=0.08
6. 多分类网络类型
7. 初始化方法为Xavier

运行结果

分类效果图

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/ch11_loss_sigmoid.png" />

训练过程中损失函数值和准确率的变化

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/ch11_result_sigmoid.png" ch="500" />

搭建模型二

使用ReLU做为激活函数的三层网络

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/ch11_net_relu.png" />

代码

```Python
def model_relu(num_input, num_hidden, num_output, hp):
    net = NeuralNet_4_0(hp, "chinabank_relu")

    fc1 = FcLayer_1_0(num_input, num_hidden, hp)
    net.add_layer(fc1, "fc1")
    r1 = ActivationLayer(Relu())
    net.add_layer(r1, "Relu1")

    fc2 = FcLayer_1_0(num_hidden, num_hidden, hp)
    net.add_layer(fc2, "fc2")
    r2 = ActivationLayer(Relu())
    net.add_layer(r2, "Relu2")

    fc3 = FcLayer_1_0(num_hidden, num_output, hp)
    net.add_layer(fc3, "fc3")
    softmax = ClassificationLayer(Softmax())
    net.add_layer(softmax, "softmax")

    net.train(dataReader, checkpoint=50, need_test=True)
    net.ShowLossHistory()
    
    ShowResult(net, hp.toString())
    ShowData(dataReader)    
```
超参数说明

1. 隐层8个神经元
2. 最大`epoch=5000`
3. 批大小=10
4. 学习率0.1
5. 绝对误差停止条件=0.08
6. 多分类网络类型
7. 初始化方法为MSRA

运行结果

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/ch11_loss_relu.png" />

训练过程中损失函数值和准确率的变化

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/ch11_result_relu.png" ch="500" />

分类效果图

使用不同的激活函数的分类结果比较

|Sigmoid|ReLU|
|---|---|
|<img src='../Images/14/ch11_result_sigmoid.png'/>|<img src='../Images/14/ch11_result_relu.png'/>|

### 14.6 多分类任务 - MNIST手写体识别

数据读取

MNIST数据本身是图像格式的，我们用`mode="vector"`去读取，转变成矢量格式。

```Python
def LoadData():
    print("reading data...")
    dr = MnistImageDataReader(mode="vector")
    ......
```
 搭建模型

一共4个隐层，都用ReLU激活函数连接，最后的输出层接Softmax分类函数。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/mnist_net.png" />

以下是主要的参数设置：

```Python
if __name__ == '__main__':
    dataReader = LoadData()
    num_feature = dataReader.num_feature
    num_example = dataReader.num_example
    num_input = num_feature
    num_hidden1 = 128
    num_hidden2 = 64
    num_hidden3 = 32
    num_hidden4 = 16
    num_output = 10
    max_epoch = 10
    batch_size = 64
    learning_rate = 0.1

    params = HyperParameters_4_0(
        learning_rate, max_epoch, batch_size,
        net_type=NetType.MultipleClassifier,
        init_method=InitialMethod.MSRA,
        stopper=Stopper(StopCondition.StopLoss, 0.12))

    net = NeuralNet_4_0(params, "MNIST")

    fc1 = FcLayer_1_0(num_input, num_hidden1, params)
    net.add_layer(fc1, "fc1")
    r1 = ActivationLayer(Relu())
    net.add_layer(r1, "r1")
    ......
    fc5 = FcLayer_1_0(num_hidden4, num_output, params)
    net.add_layer(fc5, "fc5")
    softmax = ClassificationLayer(Softmax())
    net.add_layer(softmax, "softmax")

    net.train(dataReader, checkpoint=0.05, need_test=True)
    net.ShowLossHistory(xcoord=XCoordinate.Iteration)
```

运行结果

我们设计的停止条件是绝对Loss值达到0.12时，所以迭代到6个epoch时，达到了0.119的损失值，就停止训练了。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/14/mnist_loss.png" />
训练过程中损失函数值和准确率的变化

最后用测试集得到的准确率为96.97%

## 第15章 网络优化

随着网络的加深，训练变得越来越困难，时间越来越长，原因可能是：

- 参数多
- 数据量大
- 梯度消失
- 损失函数坡度平缓

为了解决上面这些问题，科学家们在深入研究网络表现的前提下，发现在下面这些方向上经过一些努力，可以给深度网络的训练带来或多或少的改善：

- 权重矩阵初始化
- 批量归一化
- 梯度下降优化算法
- 自适应学习率算法

权重矩阵初始化

权重矩阵初始化是一个非常重要的环节，是训练神经网络的第一步，选择正确的初始化方法会带了事半功倍的效果。

零初始化

即把所有层的`W`值的初始值都设置为0。

标准初始化

标准正态初始化方法保证激活函数的输入均值为0，方差为1。将W按如下公式进行初始化：

$$
W \sim N \begin{bmatrix} 0, 1 \end{bmatrix}
$$

其中的W为权重矩阵，N表示高斯分布，Gaussian Distribution，也叫做正态分布，Normal Distribution，所以有的地方也称这种初始化为Normal初始化。

一般会根据全连接层的输入和输出数量来决定初始化的细节：

$$
W \sim N
\begin{pmatrix} 
0, \frac{1}{\sqrt{n_{in}}}
\end{pmatrix}
$$

$$
W \sim U
\begin{pmatrix} 
-\frac{1}{\sqrt{n_{in}}}, \frac{1}{\sqrt{n_{in}}}
\end{pmatrix}
$$

Xavier初始化方法

基于上述观察，Xavier Glorot等人研究出了下面的Xavier$^{[1]}$初始化方法。

条件：正向传播时，激活值的方差保持不变；反向传播时，关于状态值的梯度的方差保持不变。

$$
W \sim N
\begin{pmatrix}
0, \sqrt{\frac{2}{n_{in} + n_{out}}} 
\end{pmatrix}
$$

$$
W \sim U 
\begin{pmatrix}
 -\sqrt{\frac{6}{n_{in} + n_{out}}}, \sqrt{\frac{6}{n_{in} + n_{out}}} 
\end{pmatrix}
$$

其中的W为权重矩阵，N表示正态分布（Normal Distribution），U表示均匀分布（Uniform Distribution)。下同。

假设激活函数关于0对称，且主要针对于全连接神经网络。适用于tanh和softsign。

即权重矩阵参数应该满足在该区间内的均匀分布。其中的W是权重矩阵，U是Uniform分布，即均匀分布。

小结

几种初始化方法的应用场景

|ID|网络深度|初始化方法|激活函数|说明|
|---|---|---|---|---|
|1|单层|零初始化|无|可以|
|2|双层|零初始化|Sigmoid|错误，不能进行正确的反向传播|
|3|双层|随机初始化|Sigmoid|可以|
|4|多层|随机初始化|Sigmoid|激活值分布成凹形，不利于反向传播|
|5|多层|Xavier初始化|Tanh|正确|
|6|多层|Xavier初始化|ReLU|激活值分布偏向0，不利于反向传播|
|7|多层|MSRA初始化|ReLU|正确|

## 梯度下降优化算法

先回忆一下随机梯度下降的基本算法，便于和后面的各种算法比较。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/15/sgd_algorithm.png" />

随机梯度下降算法的梯度搜索轨迹示意图

算法

---

计算梯度：$g_t = \nabla_\theta J(\theta_{t-1})$

更新参数：$\theta_t = \theta_{t-1}  - \eta \cdot g_t$

---

随机梯度下降算法，在当前点计算梯度，根据学习率前进到下一点。到中点附近时，由于样本误差或者学习率问题，会发生来回徘徊的现象，很可能会错过最优解。

#### 实际效果

表15-3 学习率对SGD的影响

|学习率|损失函数与准确率|
|---|---|
|0.1|<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images\Images\15\op_sgd_ch09_loss_01.png">|
|0.3|<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images\Images\15\op_sgd_ch09_loss_03.png">|

SGD的另外一个缺点就是收敛速度慢，见表15-3，在学习率为0.1时，训练10000个epoch不能收敛到预定损失值；学习率为0.3时，训练5000个epoch可以收敛到预定水平。

## 自适应学习率算法

AdaGrad

AdaGrad是一个基于梯度的优化算法，它的主要功能是：它对不同的参数调整学习率，具体而言，对低频出现的参数进行大的更新，对高频出现的参数进行小的更新。因此，他很适合于处理稀疏数据。

输入和参数

- $\eta$ - 全局学习率
- $\epsilon$ - 用于数值稳定的小常数，建议缺省值为`1e-6`
- $r=0$ 初始值

算法

---

计算梯度：$g_t = \nabla_\theta J(\theta_{t-1})$

累计平方梯度：$r_t = r_{t-1} + g_t \odot g_t$

计算梯度更新：$\Delta \theta = {\eta \over \epsilon + \sqrt{r_t}} \odot g_t$

更新参数：$\theta_t=\theta_{t-1} - \Delta \theta$

---

## 算法在等高线图上的效果比较

比较

为了简化起见，我们先用一个简单的二元二次函数来模拟损失函数的等高线图，测试一下我们在前面实现的各种优化器。

$$z = \frac{x^2}{10} + y^2 \tag{1}$$

公式1是模拟均方差函数的形式，它的正向计算和反向计算的`Python`代码如下：

```Python
def f(x, y):
    return x**2 / 10.0 + y**2

def derivative_f(x, y):
    return x / 5.0, 2.0*y
```

我们依次测试4种方法：

- 普通SGD, 学习率0.95
- 动量Momentum, 学习率0.1
- RMPSProp，学习率0.5
- Adam，学习率0.5

各种算法的效果比较

|||
|---|---|
|<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images\Images\15\op_sgd_ch04.png">|<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images\Images\15\op_sgd2_ch04.png">|

## 批量归一化的原理

基本数学知识

正态分布

正态分布，又叫做高斯分布。

若随机变量$X$，服从一个位置参数为$\mu$、尺度参数为$\sigma$的概率分布，且其概率密度函数为：

$$
f(x)=\frac{1}{\sigma\sqrt{2 \pi} } e^{- \frac{{(x-\mu)^2}}{2\sigma^2}} \tag{1}
$$

则这个随机变量就称为正态随机变量，正态随机变量服从的分布就称为正态分布，记作：

$$
X \sim N(\mu,\sigma^2) \tag{2}
$$

当μ=0,σ=1时，称为标准正态分布：

$$X \sim N(0,1) \tag{3}$$

此时公式简化为：

$$
f(x)=\frac{1}{\sqrt{2 \pi}} e^{- \frac{x^2}{2}} \tag{4}
$$

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/15/bn1.png" ch="500" />

不同参数的正态分布函数曲线

深度神经网络的挑战

机器学习领域有个很重要的假设：I.I.D.（独立同分布）假设，就是假设训练数据和测试数据是满足相同分布的，这样就能做到通过训练数据获得的模型能够在测试集获得好的效果。

在深度神经网络中，我们可以将每一层视为对输入的信号做了一次变换：

$$
Z = W \cdot X + B \tag{5}
$$

批量归一化

既然可以把原始训练样本做归一化，那么如果在深度神经网络的每一层，都可以有类似的手段，也就是说把层之间传递的数据移到0点附近，那么训练效果就应该会很理想。这就是批归一化BN的想法的来源。

具体的数据处理过程如图所示

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/15/bn6.png" ch="500" />

### 15.5.4 前向计算

各个参数的含义和数据形状 

|符号|数据类型|数据形状|
|:---------:|:-----------:|:---------:|
|$X$| 输入数据矩阵 | [m, n] |
|$x_i$|输入数据第i个样本| [1, n] |
|$N$| 经过归一化的数据矩阵 | [m, n] |
|$n_i$| 经过归一化的单样本 | [1, n] |
|$\mu_B$| 批数据均值 | [1, n] |
|$\sigma^2_B$| 批数据方差 | [1, n] |
|$m$|批样本数量| [1] |
|$\gamma$|线性变换参数| [1, n] |
|$\beta$|线性变换参数| [1, n] |
|$Z$|线性变换后的矩阵| [1, n] |
|$z_i$|线性变换后的单样本| [1, n] |
|$\delta$| 反向传入的误差 | [m, n] |

如无特殊说明，以下乘法为元素乘，即element wise的乘法。

在训练过程中，针对每一个batch数据，m是批的大小。进行的操作是，将这组数据正则化，之后对其进行线性变换。

### 批量归一化的优点

1. 可以选择比较大的初始学习率，让你的训练速度提高。
2. 减少对初始化的依赖
3. 减少对正则的依赖

## 15.6 批量归一化的实现

### 15.6.1 反向传播

首先假设已知从上一层回传给批量归一化层的误差矩阵是：

$$\delta = \frac{dJ}{dZ}，\delta_i = \frac{dJ}{dz_i} \tag{10}$$

#### 求批量归一化层参数梯度

求$\gamma,\beta$的梯度：

$$\frac{dJ}{d\gamma} = \sum_{i=1}^m \frac{dJ}{dz_i}\frac{dz_i}{d\gamma}=\sum_{i=1}^m \delta_i \cdot n_i \tag{11}$$

$$\frac{dJ}{d\beta} = \sum_{i=1}^m \frac{dJ}{dz_i}\frac{dz_i}{d\beta}=\sum_{i=1}^m \delta_i \tag{12}$$

### 15.6.2 代码实现

#### 初始化类

```Python
class BnLayer(CLayer):
    def __init__(self, input_size, momentum=0.9):
        self.gamma = np.ones((1, input_size))
        self.beta = np.zeros((1, input_size))
        self.eps = 1e-5
        self.input_size = input_size
        self.output_size = input_size
        self.momentum = momentum
        self.running_mean = np.zeros((1,input_size))
        self.running_var = np.zeros((1,input_size))
```
后面三个变量，`momentum`、`running_mean`、`running_var`，是为了计算/记录历史方差均差的。

#### 前向计算

```Python
    def forward(self, input, train=True):
        ......
```
#### 反向传播

```Python
    def backward(self, delta_in, flag):
        ......
```
```Python
self.var = np.mean(self.x_mu**2, axis=0, keepdims=True) + self.eps
self.std = np.sqrt(self.var)
```
# 第16章 正则化

正则化的英文为Regularization，用于防止过拟合。

## 16.0 过拟合

### 16.0.1 拟合程度比较

在深度神经网络中，我们遇到的另外一个挑战，就是网络的泛化问题。所谓泛化，就是模型在测试集上的表现要和训练集上一样好。

神经网络的两大功能：回归和分类。
这两类任务，都会出现欠拟合和过拟合现象，如下

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/fitting.png" />

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/classification.png" />

分类任务中有三种情况，依次为：分类欠妥、正确的分类、分类过度。由于分类可以看作是对分类边界的拟合，所以我们经常也统称其为拟合。

出现过拟合的原因：

1. 训练集的数量和模型的复杂度不匹配，样本数量级小于模型的参数
2. 训练集和测试集的特征分布不一致
3. 样本噪音大，使得神经网络学习到了噪音，正常样本的行为被抑制
4. 迭代次数过多，过分拟合了训练数据，包括噪音部分和一些非重要特征

两个原因：

1. 因为有的模型以及非常成熟了，比如VGG16，可以不调参而直接用于你自己的数据训练，此时如果你的数据数量不够多，但是又想使用现有模型，就需要给模型加正则项了。
2. 使用相对复杂的模型，可以比较快速地使得网络训练收敛，以节省时间。

### 16.0.2 过拟合的例子一

充分理解过拟合的原因之后，我们先制作一个数据集，让其符合上面的第三条：制造样本噪音。但是如何制作一个合理的噪音呢？这让笔者想起了一篇讲解傅里叶变换的文章，一个复合的傅里叶变换公式可以是这样的：

$$
y = \frac{4 \sin (\theta)}{\pi} + \frac{4 \sin (5\theta)}{5\pi} \tag{1}
$$

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/sin_data.png" ch="500" />

使用MiniFramework，可以很方便地搭建起下面这个模型

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/overfitting_net_1.png" />

这个模型的复杂度要比训练样本级大很多，所以可以重现过拟合的现象，当然还需要设置好合适的参数，代码片段如下：

```Python
def SetParameters():
    num_hidden = 16
    max_epoch = 20000
    batch_size = 5
    learning_rate = 0.1
    eps = 1e-6
    
    hp = HyperParameters41(
        learning_rate, max_epoch, batch_size, eps,        
        net_type=NetType.Fitting,
        init_method=InitialMethod.Xavier, 
        optimizer_name=OptimizerName.SGD)

    return hp, num_hidden
```

我们故意把最大`epoch`次数设置得比较大，以充分展示过拟合效果。训练结束后，首先看损失函数值和精度值的变化曲线

偏差与方差

(do be add more...)

### 16.1.1 直观的解释

先用一个直观的例子来理解偏差和方差。比如打靶，如图16-9所示。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/variance_bias.png" width="600" ch="500" />

图16-9 打靶中的偏差和方差

总结一下，不同偏差和方差反映的射手的特点如表16-1所示。

表16-1 不同偏差和方差的射手特点

||低偏差|高偏差|
|---|---|---|
|低方差|射手很稳，枪的准星也很准。|射手很稳，但是枪的准星有问题，所有子弹都固定地偏向一侧。|
|高方差|射手不太稳，但枪的准星没问题，虽然弹着点分布很散，但没有整体偏移。|射手不稳，而且枪的准星也有问题，弹着点分布很散且有规律地偏向一侧。|

### 16.1.2 神经网络训练的例子

我们在前面讲过数据集的使用，包括训练集、验证集、测试集。在训练过程中，我们要不断监测训练集和验证集在当前模型上的误差，和上面的打靶的例子一样，有可能产生四种情况，如表16-2所示。

表16-2 不同偏差和方差反映的四种情况

|情况|训练集误差A|验证集误差B|偏差|方差|说明|
|---|---|---|---|---|---|
|情况1|1.5%|1.7%|低偏差|低方差|A和B都很好，适度拟合|
|情况2|12.3%|11.4%|高偏差|低方差|A和B都很不好，欠拟合|
|情况3|1.2%|13.1%|低偏差|高方差|A很好，但B不好，过拟合|
|情况4|12.3%|21.5%|高偏差|高方差|A不好，B更不好，欠拟合|

在本例中，偏差衡量训练集误差，方差衡量训练集误差和验证集误差的比值。

上述四种情况的应对措施：

- 情况1
  
  效果很好，可以考虑进一步降低误差值，提高准确度。

- 情况2

  训练集和验证集同时出现较大的误差，有可能是：迭代次数不够、数据不好、网络设计不好，需要继续训练，观察误差变化情况。

- 情况3

  训练集的误差已经很低了，但验证集误差很高，说明过拟合了，即训练集中的某些特殊样本影响了网络参数，但类似的样本在验证集中并没有出现

- 情况4

  两者误差都很大，目前还看不出来是什么问题，需要继续训练

### 16.1.3 偏差-方差分解

除了用上面的试验来估计泛化误差外，我们还希望在理论上分析其必然性，这就是偏差-方差分解的作用，bias-variance decomposition。表16-3是本章中使用的符号的含义，后续在推导公式的时候会用到。

表16-3 符号含义

|符号|含义|
|---|---|
|$x$|测试样本|
|$D$|数据集|
|$y$|x的真实标记|
|$y_D$|x在数据集中标记(可能有误差)|
|$f$|从数据集D学习的模型|
|$f_{x;D}$|从数据集D学习的模型对x的预测输出|
|$f_x$|模型f对x的期望预测输出|

学习算法期望的预测：
$$f_x=E[f_{x;D}] \tag{1}$$
不同的训练集/验证集产生的预测方差：
$$var(x)=E[(f_{x;D}-f_x)^2] \tag{2}$$
噪声：
$$\epsilon^2=E[(y_D-y)^2] \tag{3}$$
期望输出与真实标记的偏差：
$$bias^2(x)=(f_x-y)^2 \tag{4}$$
算法的期望泛化误差：

$$
\begin{aligned}
E(f;D)&=E[(f_{x;D}-y_D)^2]=E[(f_{x;D}-f_x+f_x-y_D)^2] \\\\
&=E[(f_{x;D}-f_x)^2]+E[(f_x-y_D)^2]+E[2(f_{x;D}-f_x)(f_x-y_D)]=E[(f_{x;D}-f_x)^2]+E[(f_x-y_D)^2] \\\\
&=E[(f_{x;D}-f_x)^2]+E[(f_x-y+y-y_D)^2]=E[(f_{x;D}-f_x)^2]+E[(f_x-y)^2]+E(y-y_D)^2]+E[2(f_x-y)(y-y_D)] \\\\
&=E[(f_{x;D}-f_x)^2]+(f_x-y)^2+E[(y-y_D)^2]=var(x) + bias^2(x) + \epsilon^2
\end{aligned}
$$

所以，各个项的含义是：

- 偏差：度量了学习算法的期望与真实结果的偏离程度，即学习算法的拟合能力。
- 方差：训练集与验证集的差异造成的模型表现的差异。
- 噪声：当前数据集上任何算法所能到达的泛化误差的下线，即学习问题本身的难度。

想当然地，我们希望偏差与方差越小越好，但实际并非如此。一般来说，偏差与方差是有冲突的，称为偏差-方差窘境 (bias-variance dilemma)。

- 给定一个学习任务，在训练初期，由于训练不足，网络的拟合能力不够强，偏差比较大，也是由于拟合能力不强，数据集的特征也无法使网络产生显著变化，也就是欠拟合的情况。
- 随着训练程度的加深，网络的拟合能力逐渐增强，训练数据的特征也能够渐渐被网络学到。
- 充分训练后，网络的拟合能力已非常强，训练数据的微小特征都会导致网络发生显著变化，当训练数据自身的、非全局的特征被网络学到了，则将发生过拟合。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/error.png" width="600" ch="500" />

图16-10 训练过程中的偏差和方差变化

在图16-10中，随着训练程度的增加，偏差（点线）一路下降，但是方差（虚线）一路上升，整体误差（实线，偏差+方差+噪音误差）呈U形，最佳平衡点就是U形的最低点。

### 16.1.4 没有免费午餐定理

没有免费午餐定理（No Free Lunch Theorem，NFL）是由Wolpert和Macerday在最优化理论中提出的。没有免费午餐定理证明：对于基于迭代的最优化算法，不存在某种算法对所有问题（有限的搜索空间内）都有效。如果一个算法对某些问题有效，那么它一定在另外一些问题上比纯随机搜索算法更差。

还可以理解为在所有可能的数据生成分布上平均之后，每一个分类算法在未事先观测的点上都有相同的错误率。也就是说，不能脱离具体问题来谈论算法的优劣，任何算法都有局限性。必须要“具体问题具体分析”。

没有免费午餐定理对于机器学习算法也同样适用。不存在一种机器学习算 法适合于任何领域或任务。如果有人宣称自己的模型在所有问题上都好于其他模型，那么他肯定是在吹牛。

## 16.2 L2正则

从过拟合的现象分析，是因为神经网络的权重矩阵参数过度地学习，即针对训练集，其损失函数值已经逼近了最小值。
用熟悉的等高线图来解释

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/regular0.png" />

假设只有两个参数需要学习，那么这两个参数的损失函数就构成了上面的等高线图。由于样本数据量比较小（这是造成过拟合的原因之一），所以神经网络在训练过程中沿着箭头方向不断向最优解靠近，最终达到了过拟合的状态。也就是说在这个等高线图中的最优解，实际是针对有限的样本数据的最优解，而不是针对这个特点问题的最优解。

范数

基本概念：

$$L_p = \lVert x \rVert_p = ({\sum^n_{i=1}\lvert x_i \rvert^p})^{1/p} \tag{1}$$

范数包含向量范数和矩阵范数，我们只关心向量范数。我们用具体的数值来理解范数。

高斯分布

$$
f(x)=\frac{1}{\sigma\sqrt{2 \pi}} \exp{- \frac{(x-\mu)^2}{2\sigma^2}} \tag{2}
$$

L2正则化

假设：

- W参数服从高斯分布，即：$w_j \sim N(0,\tau^2)$
- Y服从高斯分布，即：$y_i \sim N(w^Tx_i,\sigma^2)$

贝叶斯最大后验估计：

$$
\arg\max_wL(w) = \ln \prod_i^n \frac{1}{\sigma\sqrt{2 \pi}}\exp(-(\frac{y_i-w^Tx_i}{\sigma})^2/2) \cdot \prod_j^m{\frac{1}{\tau\sqrt{2\pi}}\exp(-(\frac{w_j}{\tau})^2/2)}
$$

$$
=-\frac{1}{2\sigma^2}\sum_i^n(y_i-w^Tx_i)^2-\frac{1}{2\tau^2}\sum_j^m{w_j^2}-n\ln\sigma\sqrt{2\pi}-m\ln \tau\sqrt{2\pi} \tag{3}
$$

因为$\sigma,b,n,\pi,m$等都是常数，所以损失函数$J(w)$的最小值可以简化为：

$$
\arg\min_wJ(w) = \sum_i^n(y_i-w^Tx_i)^2+\lambda\sum_j^m{w_j^2} \tag{4}
$$

看公式4，相当于是线性回归的均方差损失函数，再加上一个正则项（也称为惩罚项），共同构成损失函数。如果想求这个函数的最小值，则需要两者协调，并不是说分别求其最小值就能实现整体最小，因为它们具有共同的W项，当W比较大时，第一项比较小，第二项比较大，或者正好相反。所以它们是矛盾组合体。

损失函数的变化

假设是均方差损失函数：

$$J(w,b)=\frac{1}{2m}\sum_{i=1}^m (z_i-y_i)^2 + \frac{\lambda}{2m}\sum_{j=1}^n{w_j^2} \tag{5}$$

如果是交叉熵损失函数：

$$J(w,b)= -\frac{1}{m} \sum_{i=1}^m [y_i \ln a_i + (1-y_i) \ln (1-a_i)]+ \frac{\lambda}{2m}\sum_{j=1}^n{w_j^2} \tag{6}$$

反向传播的变化

由于正则项是在损失函数中，在正向计算中，并不涉及到它，所以正向计算公式不用变。但是在反向传播过程中，需要重新推导一下公式。

假设有一个两层的回归神经网络，其前向计算如下：

$$
Z1 = W1 \cdot X + B1 \tag{5}
$$
$$
A1 = Sigmoid(Z1) \tag{6}
$$
$$
Z2 = W2 \cdot A1 + B2 \tag{7}
$$
$$
J(w,b)=\frac{1}{2m}[\sum_{i=1}^m (z_i-y_i)^2 + \lambda\sum_{j=1}^n{w_j^2}]  \tag{8}
$$
从公式8求Z2的误差矩阵：
$$
dZ2 = \frac{dJ}{dZ2}=Z2-Y
$$
从公式8求W2的误差矩阵，因为有正则项存在，所以需要附加一项：
$$
\begin{aligned}
\frac{dJ}{dW2}&=\frac{dJ}{dZ2}\frac{dZ2}{dW2}+\frac{dJ}{dW2}
\\
&=(Z2-Y)\cdot A1^T+\lambda \odot W2 
\end{aligned}
\tag{9}
$$

公式8是W1,W2的总和，公式9对dJ/dW2求导时，由于是$W1^2+W2^2$的关系，所以W1对W2求导的结果是0，所以公式9最后只剩下W2了。

运行结果

下面是主程序的运行代码：

```Python
from Level0_OverFitNet import *

if __name__ == '__main__':
    dr = LoadData()
    hp, num_hidden = SetParameters()
    hp.regular_name = RegularMethod.L2
    hp.regular_value = 0.01
    net = Model(dr, 1, num_hidden, 1, hp)
    ShowResult(net, dr, hp.toString())
```

运行后，将训练过程中的损失和准确率可视化出来，并将拟合后的曲线与训练数据做比较，如图所示。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/L2_sin_loss.png" />

训练过程中损失函数值和准确率的变化曲线

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/L2_sin_result.png" ch="500" />

拟合后的曲线与训练数据的分布图

## L1正则

### 16.3.1 另一个朴素的想法

我们把熟悉的等高线图拿出来再看一眼，如图16-16所示。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/regular0.png" />

图16-16 损失函数值的等高线图

假设只有两个参数需要学习，那么这两个参数的损失函数就构成了上面的等高线图。

在L2正则中，我们想办法让W的值都变得比较小，这样就不会对特征敏感。但是也会杀敌一千，自损八百，连有用特征一起被忽视掉了。那么换个思路，能不能让神经网络自动选取有用特征，忽视无用特征呢？也就是让有用特征的权重比较大，让无用特征的权重比较小，甚至为0。

用上面的图举例，公式为：

$$z=x_1 \cdot w_1 + x_2 \cdot w_2 + b$$

假设$x_1$是无用特征，想办法让$w_1$变得很小或者是0，就会得到比较满意的模型。这种想法在只有两个特征值时不明显，甚至不正确，但是当特征值有很多时，比如MNIST数据中的784个特征，肯定有些是非常重要的特征，有些是没什么用的特征。

拉普拉斯分布

$$
\begin{aligned}
f(x)&=\frac{1}{2b}\exp(-\frac{|x-\mu|}{b})\\\\
&= \frac{1}{2b} \begin{cases} \exp(\frac{x-\mu}{b}), & x \lt \mu \\\\ \exp(\frac{\mu-x}{b}), & x \gt \mu \end{cases}
\end{aligned}
$$

#### L0范数与L1范数

L0范数是指向量中非0的元素的个数。如果我们用L0范数来规则化一个参数矩阵W的话，就是希望W的大部分元素都是0，即让参数W是稀疏的。

L1范数是指向量中各个元素绝对值之和，也叫“稀疏规则算子”（Lasso regularization）。为什么L1范数会使权值稀疏？有人可能会这样给你回答“它是L0范数的最优凸近似”。实际上，还存在一个更美的回答：任何的规则化算子，如果他在$w_i=0$的地方不可微，并且可以分解为一个“求和”的形式，那么这个规则化算子就可以实现稀疏。w的L1范数是绝对值，所以$|w|$在$w=0$处是不可微。

为什么L0和L1都可以实现稀疏，但常用的为L1？一是因为L0范数很难优化求解，二是L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解。所以大家才把目光转于L1范数。

综上，L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用。

L1正则化

假设：

- W参数服从拉普拉斯分布，即$w_j \sim Laplace(0,b)$
- Y服从高斯分布，即$y_i \sim N(w^Tx_i,\sigma^2)$

贝叶斯最大后验估计：
$$
\begin{aligned}
\arg\max_wL(w) = &\ln \prod_i^n \frac{1}{\sigma\sqrt{2 \pi}}\exp(-\frac{1}{2}(\frac{y_i-w^Tx_i}{\sigma})^2) 
\cdot \prod_j^m{\frac{1}{2b}\exp(-\frac{\lvert w_j \rvert}{b})}
\\\\
=&-\frac{1}{2\sigma^2}\sum_i^n(y_i-w^Tx_i)^2-\frac{1}{2b}\sum_j^m{\lvert w_j \rvert}
-n\ln\sigma\sqrt{2\pi}-m\ln b\sqrt{2\pi} 
\end{aligned}
\tag{1}
$$

因为$\sigma,b,n,\pi,m$等都是常数，所以损失函数$J(w)$的最小值可以简化为：

$$
\arg\min_wJ(w) = \sum_i^n(y_i-w^Tx_i)^2+\lambda\sum_j^m{\lvert w_j \rvert} \tag{2}
$$

我们仍以两个参数为例，公式2的后半部分的正则形式为：

$$L_1 = \lvert w_1 \rvert + \lvert w_2 \rvert \tag{3}$$

因为$w_1,w_2$有可能是正数或者负数，我们令$x=|w_1|,y=|w_2|,c=L_1$，则公式3可以拆成以下4个公式的组合：

$$
y=-x+c \quad (当w_1 \gt 0, w_2 \gt 0时)
$$
$$
y=\quad x+c \quad (当w_1 \lt 0, w_2 \gt 0时)
$$
$$
y=\quad x-c \quad (当w_1 \gt 0, w_2 \lt 0时)
$$
$$
y=-x-c \quad (当w_1 \lt 0, w_2 \lt 0时)
$$

所以上述4个公式（4条直线）会组成一个二维平面上的一个菱形。

损失函数的变化

假设我们以前使用的损失函数为$J_0$，则新的损失函数变成：

$$J = J_0 + \frac{\lambda}{m} \sum_i^m \lvert w_i \rvert$$

代码片段如下：

```Python
  regular_cost = 0
  for i in range(self.layer_count-1,-1,-1):
      layer = self.layer_list[i]
      if isinstance(layer, FcLayer):
          if regularName == RegularMethod.L1:
              regular_cost += np.sum(np.abs(layer.weights.W))
          elif regularName == RegularMethod.L2:
              regular_cost += np.sum(np.square(layer.weights.W))
      # end if
  # end for
  return regular_cost * self.params.lambd
```

可以看到L1部分的代码，先求绝对值，再求和。那个分母上的m是在下一段代码中处理的，因为在上一段代码中，没有任何样本数量的信息。

```Python
loss_train = self.lossFunc.CheckLoss(train_y, self.output)
loss_train += regular_cost / train_y.shape[0]
```
`train_y.shape[0]`就是样本数量。

### 16.3.5 反向传播的变化

假设一个两层的神经网络，其前向过程是：

$$Z1=W1 \cdot X + B1$$
$$A1 = Sigmoid(Z1)$$
$$Z2=W2 \cdot A1 + B2$$
$$J(w,b) = J_0 + \lambda (\lvert W1 \rvert+\lvert W2 \rvert)$$

则反向过程为：

$$
\begin{aligned}
dW2&=\frac{dJ}{dW2}=\frac{dJ}{dZ2}\frac{dZ2}{dW2}+\frac{dJ}{dW2} \\\\
&=dZ2 \cdot A1^T+\lambda \odot sign(W2)
\end{aligned}
$$
$$dW1= dZ1 \cdot X^T + \lambda \odot sign(W1) $$

从上面的公式中可以看到，正则项在方向传播过程中，唯一影响的就是求W的梯度时，要增加一个$\lambda \odot sign(W)$，sign是符号函数，返回该值的符号，即1或-1。所以，我们可以修改`FullConnectionLayer.py`中的反向传播函数如下：

```Python
def backward(self, delta_in, idx):
    dZ = delta_in
    m = self.x.shape[1]
    if self.regular == RegularMethod.L2:
        self.weights.dW = (np.dot(dZ, self.x.T) + self.lambd * self.weights.W) / m
    elif self.regular == RegularMethod.L1:
        self.weights.dW = (np.dot(dZ, self.x.T) + self.lambd * np.sign(self.weights.W)) / m
    else:
        self.weights.dW = np.dot(dZ, self.x.T) / m
    # end if
    self.weights.dB = np.sum(dZ, axis=1, keepdims=True) / m
    ......
```
符号函数的效果如下：
```Python
>>> a=np.array([1,-1,2,0])
>>> np.sign(a)
>>> array([ 1, -1,  1,  0])
```
当w为正数时，符号为正，值为1，相当于直接乘以w的值；当w为负数时，符号为负，值为-1，相当于乘以(-w)的值。最后的效果就是乘以w的绝对值。

运行结果

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/L1_sin_loss.png" />

训练过程中损失函数值和准确率的变化曲线

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/L1_sin_result.png" ch="500" />

拟合后的曲线与训练数据的分布图

从输出结果分析：

1. 权重值的绝对值和等于391.26，远小于过拟合时的1719
2. 较小的权重值（小于0.01）的数量为22935个，远大于过拟合时的2810个
3. 趋近于0的权重值（小于0.0001）的数量为12384个，大于过拟合时的25个。

L1的优势：

1. 特征选择(Feature Selection)
2. 可解释性(Interpretability)

L1和L2的比较

表16-4展示了L1和L2两种正则方法的比较项目。

表16-4 L1和L2的比较

|比较项|无正则项|L2|L1|
|---|---|---|---|
|代价函数|$J(w,b)$|$J(w,b)+\lambda \Vert w \Vert^2_2$|$J(w,b)+\lambda \Vert w \Vert_1$|
|梯度计算|$dw$|$dw+\lambda \cdot w/m$|$dw+\lambda \cdot sign(w)/m$|
|准确率|0.961|0.982|0.987||
|总参数数量|544|544|544|
|小值参数数量(<1e-2)|7|204|524|
|极小值参数数量(<1e-5)|0|196|492|
|第1层参数Norm1|8.66|6.84|4.09|
|第2层参数Norm1|104.26|34.44|6.38|
|第3层参数Norm1|97.74|18.96|6.73|
|第4层参数Norm1|9.03|4.22|4.41|
|第1层参数Norm2|2.31|1.71|1.71|
|第2层参数Norm2|6.81|2.15|2.23|
|第3层参数Norm2|5.51|2.45|2.81|
|第4层参数Norm2|2.78|2.13|2.59|

## 早停法 Early Stopping

### 16.4.1 想法的由来

从图16-20来看，如果我们在第2500次迭代时就停止训练，就应该是验证集的红色曲线的最佳取值位置了，因为此时损失值最小，而准确率值最大。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/overfitting_sin_loss.png" />

图16-20 训练过程中损失函数值和准确率的变化曲线

理论基础

早停法，实际上也是一种正则化的策略，可以理解为在网络训练不断逼近最优解的过程种（实际上这个最优解是过拟合的），在梯度等高线的外围就停止了训练，所以其原理上和L2正则是一样的，区别在于得到解的过程。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/regular0.png" />

损失函数值的等高线图

算法

一般的做法是，在训练的过程中，记录到目前为止最好的validation 准确率，当连续N次Epoch（比如N=10或者更多次）没达到最佳准确率时，则可以认为准确率不再提高了。此时便可以停止迭代了（Early Stopping）。这种策略也称为“No-improvement-in-N”，N即Epoch的次数，可以根据实际情况取，如10、20、30……

实现

```Python
class TrainingTrace(object):
    def __init__(self, need_earlyStop = False, patience = 5):
        ......
        # for early stop
        self.early_stop = need_earlyStop
        self.patience = patience
        self.patience_counter = 0
        self.last_vld_loss = float("inf")

    def Add(self, epoch, total_iteration, loss_train, accuracy_train, loss_vld, accuracy_vld):
        ......
        if self.early_stop:
            if loss_vld < self.last_vld_loss:
                self.patience_counter = 0
                self.last_vld_loss = loss_vld
            else:
                self.patience_counter += 1
                if self.patience_counter >= self.patience:
                    return True     # need to stop
            # end if
        return False
```

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/EarlyStop_sin_loss.png" />

训练过程中损失函数值和准确率的变化曲线

早停法并不会提高准确率，而只是在最高的准确率上停止训练（前提是知道后面的训练会造成过拟合），从上图可以看到，最高的准确率是99.07%，达到了我们的目的。

最后的拟合效果如图16-23所示。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/EarlyStop_sin_result.png" ch="500" />

拟合后的曲线与训练数据的分布图

蓝点是样本，绿点是理想的拟合效果，红线是实际的拟合效果。

后续的步骤

#### 彻底停止

就是啥也不做了，最多再重复几次早停的试验，看看是不是稳定，然后就使用$\theta_{best}$做为训练结果。

#### 再次训练

由于第一次早停是通过验证集计算loss值来实现的，所以这次不再分训练集和验证集，记住了早停时的迭代次数，可以重新初始化权重矩阵参数，使用所有数据再次训练，然后到达第一次的$i_{best}$时停止。

#### 继续训练

得到$\theta_{best}$后，用全部训练数据（不再分训练集和验证集），在此基础上继续训练若干轮，并且继续用以前的验证集来监控损失函数值，如果能得到比以前更低的损失值，将会是比较理想的情况。

丢弃法 Dropout

### 16.5.1 基本原理

假设原来的神经网络是这个结构，最后输出三分类结果，如图所示。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/dropout_before.png" />

输出三分类的神经网络结构图

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/dropout_after.png" />

使用丢弃法的神经网络结构图

算法与实现

#### 前向计算

正常的隐层计算公式是：

$$
Z = W \cdot X + B \tag{1}
$$

加入随机丢弃步骤后，变成了：

$$
r \sim Bernoulli(p) \tag{2}
$$
$$Y = r \cdot X \tag{3}$$
$$Z = Y \cdot W + B \tag{4}
$$

#### 代码实现

```Python
class DropoutLayer(CLayer):
    def __init__(self, input_size, ratio=0.5):
        self.dropout_ratio = ratio
        self.mask = None
        self.input_size = input_size
        self.output_size = input_size

    def forward(self, input, train=True):
        assert(input.ndim == 2)
        if train:
            self.mask = np.random.rand(*input.shape) > self.dropout_ratio
            self.z = input * self.mask
        else:
            self.z = input * (1.0 - self.dropout_ratio)

        return self.z
       
    def backward(self, delta_in, idx):
        delta_out = self.mask * delta_in
        return delta_out
```

写好`Dropout`层后，我们在原来的模型的基础上，搭建一个带`Dropout`层的新模型，代码如下

```Python
def Model_Dropout(dataReader, num_input, num_hidden, num_output, params):
    net = NeuralNet41(params, "overfitting")

    fc1 = FcLayer(num_input, num_hidden, params)
    net.add_layer(fc1, "fc1")
    s1 = ActivatorLayer(Sigmoid())
    net.add_layer(s1, "s1")
    
    d1 = DropoutLayer(num_hidden, 0.1)
    net.add_layer(d1, "d1")

    fc2 = FcLayer(num_hidden, num_hidden, params)
    net.add_layer(fc2, "fc2")
    t2 = ActivatorLayer(Tanh())
    net.add_layer(t2, "t2")

    #d2 = DropoutLayer(num_hidden, 0.2)
    #net.add_layer(d2, "d2")

    fc3 = FcLayer(num_hidden, num_hidden, params)
    net.add_layer(fc3, "fc3")
    t3 = ActivatorLayer(Tanh())
    net.add_layer(t3, "t3")

    d3 = DropoutLayer(num_hidden, 0.2)
    net.add_layer(d3, "d3")
    
    fc4 = FcLayer(num_hidden, num_output, params)
    net.add_layer(fc4, "fc4")

    net.train(dataReader, checkpoint=100, need_test=True)
    net.ShowLossHistory(XCoordinate.Epoch)
    
    return net
``` 

运行程序，最后可以得到这样的损失函数图和验证结果，如图所示。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/dropout_sin_loss.png" />

训练过程中损失函数值和准确率的变化曲线

可以提高精确率到98.17%。

拟合效果如图所示。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/dropout_sin_result.png" ch="500" />

拟合后的曲线与训练数据的分布图

### 16.6.2 在增强数据集上训练

只需要在`Level0`的代码基础上，修改数据集操作部分，就可以使用增强后的数据进行训练，以下是训练结果。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/data_result.png" />

图16-33 训练过程中损失函数值和准确率的变化曲线

```
epoch=199, total_iteration=17910
loss_train=0.0001, accuracy_train=1.000000
loss_valid=0.3276, accuracy_valid=0.942000
epoch=199, total_iteration=17999
loss_train=0.0001, accuracy_train=1.000000
loss_valid=0.3279, accuracy_valid=0.942000
time used: 28.778401613235474
total weights abs sum= 2010.710018228446
total weights = 26520
little weights = 2613
zero weights = 29
testing...
rate=9016 / 10000 = 0.9016
```

在图16-33中可以看到还是有些过拟合的现象方式，实际上这不是数据的问题，而是这个网络太复杂，即使用原始的MNIST数据集训练，也是会过拟合的。

但是，我们可以对比图16-34所示的数据增强之前的1000个样本的训练结果。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/overfit_result.png" />

图16-34 数据增强之前的损失函数值和准确率的变化曲线

```
epoch=199, total_iteration=1799
loss_train=0.0015, accuracy_train=1.000000
loss_valid=0.9956, accuracy_valid=0.860000
time used: 5.082462787628174
total weights abs sum= 1722.470655813152
total weights = 26520
little weights = 2815
zero weights = 27
testing...
rate=8423 / 10000 = 0.8423
```
通过对比可以发现：

1. 过拟合现象极大程度地消减了，从损失函数的U型曲线的角度可以看出来
2. 我们使用了原始的MNIST数据集中的测试集来测试两个模型：
>> - 原始1000个样本的模型的测试结果是84.23%
>> - 增强后的10000个样本的模型的测试结果是90.16%

数据增强后的样本在真实的测试数据下，准确率比增强前的样本高了很多，说明数据增强起到了很大的作用。

### 16.6.3 多样本合成法

#### SMOTE

SMOTE,Synthetic Minority Over-sampling Technique$^{[1]}$，通过人工合成新样本来处理样本不平衡问题，提升分类器性能。

类不平衡现象是数据集中各类别数量不近似相等。如果样本类别之间相差很大，会影响分类器的分类效果。假设小样本数据数量极少，仅占总体的1%，所能提取的相应特征也极少，即使小样本被错误地全部识别为大样本，在经验风险最小化策略下的分类器识别准确率仍能达到99%，但在验证环节分类效果不佳。

基于插值的SMOTE方法为小样本类合成新的样本，主要思路为：

1. 定义好特征空间，将每个样本对应到特征空间中的某一点，根据样本不平衡比例确定采样倍率N；
2. 对每一个小样本类样本$(x,y)$，按欧氏距离找K个最近邻样本，从中随机选取一个样本点，假设选择的近邻点为$(x_n,y_n)$。在特征空间中样本点与最近邻样本点的连线段上随机选取一点作为新样本点，满足以下公式:

$$(x_{new},y_{new})=(x,y)+rand(0,1)\times ((x_n-x),(y_n-y))$$

3. 重复选取取样，直到大、小样本数量平衡。

在`python`中，SMOTE算法已经封装到了`imbalanced-learn`库中。

#### SamplePairing

SamplePairing$^{[2]}$方法的处理流程如图16-35所示，从训练集中随机抽取两张图片分别经过基础数据增强操作（如随机翻转等）处理后经像素取平均值的形式叠加合成一个新的样本，标签为原样本标签中的一种。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/sample_pairing.png" />

图16-35 SamplePairing方法的处理流程

经SamplePairing处理后可使训练集的规模从N扩增到N*N，在CPU上也能完成处理。

训练过程是交替禁用与使用SamplePairing处理操作的结合：

1. 使用传统的数据增强训练网络，不使用SamplePairing 数据增强训练。
2. 在ILSVRC数据集上完成一个epoch或在其他数据集上完成100个epoch后，加入SamplePairing 数据增强训练。
3. 间歇性禁用 SamplePairing。对于 ILSVRC 数据集，为其中的300000 个图像启用SamplePairing，然后在接下来的100000个图像中禁用它。对于其他数据集，在开始的8个epoch中启用，在接下来的2个epoch中禁止。
4. 在训练损失函数和精度稳定后进行微调，禁用SamplePairing。

实验结果表明，因SamplePairing数据增强操作可能引入不同标签的训练样本，导致在各数据集上使用SamplePairing训练的误差明显增加，而在检测误差方面使用SamplePairing训练的验证误差有较大幅度降低。

尽管SamplePairing思路简单，性能上提升效果可观，符合奥卡姆剃刀原理，遗憾的是的可解释性不强，目前尚缺理论支撑。目前仅有图片数据的实验，还需下一步的实验与解读。

#### Mixup

Mixup$^{[3]}$是基于邻域风险最小化（VRM）原则的数据增强方法，使用线性插值得到新样本数据。在邻域风险最小化原则下，根据特征向量线性插值将导致相关目标线性插值的先验知识，可得出简单且与数据无关的mixup公式：

$$
x_n=\lambda x_i + (1-\lambda)x_j \\\\
y_n=\lambda y_i + (1-\lambda)y_j
$$

其中$(x_n，y_n)$是插值生成的新数据，$(x_i,y_i)$和$(x_j，y_j)$是训练集中随机选取的两个数据，λ的取值满足贝塔分布，取值范围介于0到1，超参数α控制特征目标之间的插值强度。

Mixup的实验丰富，实验结果表明可以改进深度学习模型在ImageNet数据集、CIFAR数据集、语音数据集和表格数据集中的泛化误差，降低模型对已损坏标签的记忆，增强模型对对抗样本的鲁棒性和训练对抗生成网络的稳定性。

Mixup处理实现了边界模糊化，提供平滑的预测效果，增强模型在训练数据范围之外的预测能力。随着超参数α增大，实际数据的训练误差就会增加，而泛化误差会减少。说明Mixup隐式地控制着模型的复杂性。随着模型容量与超参数的增加，训练误差随之降低。

尽管有着可观的效果改进，但mixup在偏差—方差平衡方面尚未有较好的解释。在其他类型的有监督学习、无监督、半监督和强化学习中，Mixup还有很大的发展空间。

#### 小结

Mixup、SMOTE、SamplePairing三者思路上有相同之处，都是试图将离散样本点连续化来拟合真实样本分布，但所增加的样本点在特征空间中仍位于已知小样本点所围成的区域内。但在特征空间中，小样本数据的真实分布可能并不限于该区域中，在给定范围之外适当插值，也许能实现更好的数据增强效果。

## 16.6 数据增强 Data Augmentation

过拟合的原因之一是训练数据不够，而在现代的机器学习中，数据量却是不成问题，因为通过互联网上用户的交互行为，或者和手机App的交互行为，可以收集大量的数据用于网络训练。

但是对于一些图片类数据，不是很容易从原始渠道搞到，所以可以采用增加一些假数据的方式来满足需要，尤其是当这个任务是分类任务时，更加适合。

对于拟合任务，在当前样本数据附近增加一些假的样本数据并无意义，相当于把整个样本数据变“粗”。对于概率密度计算任务，增加假样本很可能破坏原始样本的概率密度。

通过丰富的图像处理手段，我们往往可以把样本数量翻好几倍。下面我们通过手写数字识别的例子，来说明如何做简单的图片增强。

### 16.6.1 图像数据增强

#### 旋转

定义图片中心和旋转角度，进行微小的旋转。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/data_rotate.png" />

图16-30 原始图片与旋转后的图片

图16-30中，中间的是原始图片，左右是旋转后的图片。

选择操作的代码：

```Python
def rotate(image, angle):
    height, width = image.shape
    center = (height // 2, width // 2)
    rotation = cv2.getRotationMatrix2D(center, angle, 1)
    rotated_image = cv2.warpAffine(image, rotation, (width, height))
    return rotated_image
```
在调用上面的代码时，angle=10或者-10，相当于向左或向右旋转10度。

#### 缩放

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/data_stretch.png" ch="500" />

图16-31 原始图片与缩放后的图片

图16-31中各部分的图片分别是：

- 上：水平方向放大到1.2倍
- 左：垂直方向放大到1.2倍
- 中：原始图片
- 右：垂直方向缩小到0.8倍
- 下：水平方向缩小到0.8倍

#### 平移和添加噪音

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/data_translate.png" ch="500" />

图16-32 原始图片与平移后的图片、带噪声的图片

图16-32中各部分的图片分别是：

- 上左：原始图片
- 上右：向下平移2像素
- 下左：向右平移2像素
- 下右：添加噪音

平移操作的代码：
```Python
def translate(image, distance, direction=0):
    height, width = image.shape

    if direction == 0:
        M = np.float32([[1, 0, 0], [0, 1, distance]])
    else:
        M = np.float32([[1, 0, distance], [0, 1, 0]])
    # end if

    return cv2.warpAffine(image, M, (width, height))
```    

添加噪音的代码：
```Python
def noise(image, var=0.1):
    gaussian_noise = np.random.normal(0, var ** 0.5, image.shape)
    noise_image = image + gaussian_noise
    return np.clip(noise_image, 0, 1)
```

做完上述变换后，我们得到了额外的9000个数据，连同原始的1000个数据一起保存在.npz文件中，供后面使用。

#### 其它图像处理方法

- 翻转图像：即左右镜像，或者上下镜像，但是对于数字识别来说不合适
- 剪裁图像：从图像中随机选择一部分，再调整为原始图像大小，对于本例也不适合
- 颜色变化：对图像进行颜色抖动，即对RGB值进行随机扰动，如椒盐噪声和高斯噪声
- 对比度变化：通过修改HSV空间中的色调和饱和度来改变图像的对比度，也可以用直方图均衡化
- 亮度变化：改变整个图像的亮度
- 颜色增强：对于颜色暗淡的图片进行全图的颜色增强

以上这些方法，其实就相当于用照相机在不同的角度、光线、背景、远近的条件下，对目标数据进行再次采样，所以从原理上来说是完全合理的。

### 16.6.2 在增强数据集上训练

只需要在`Level0`的代码基础上，修改数据集操作部分，就可以使用增强后的数据进行训练，以下是训练结果。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/data_result.png" />

图16-33 训练过程中损失函数值和准确率的变化曲线

```
epoch=199, total_iteration=17910
loss_train=0.0001, accuracy_train=1.000000
loss_valid=0.3276, accuracy_valid=0.942000
epoch=199, total_iteration=17999
loss_train=0.0001, accuracy_train=1.000000
loss_valid=0.3279, accuracy_valid=0.942000
time used: 28.778401613235474
total weights abs sum= 2010.710018228446
total weights = 26520
little weights = 2613
zero weights = 29
testing...
rate=9016 / 10000 = 0.9016
```

在图16-33中可以看到还是有些过拟合的现象方式，实际上这不是数据的问题，而是这个网络太复杂，即使用原始的MNIST数据集训练，也是会过拟合的。

但是，我们可以对比图16-34所示的数据增强之前的1000个样本的训练结果。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/overfit_result.png" />

图16-34 数据增强之前的损失函数值和准确率的变化曲线

```
epoch=199, total_iteration=1799
loss_train=0.0015, accuracy_train=1.000000
loss_valid=0.9956, accuracy_valid=0.860000
time used: 5.082462787628174
total weights abs sum= 1722.470655813152
total weights = 26520
little weights = 2815
zero weights = 27
testing...
rate=8423 / 10000 = 0.8423
```
通过对比可以发现：

1. 过拟合现象极大程度地消减了，从损失函数的U型曲线的角度可以看出来
2. 我们使用了原始的MNIST数据集中的测试集来测试两个模型：
>> - 原始1000个样本的模型的测试结果是84.23%
>> - 增强后的10000个样本的模型的测试结果是90.16%

数据增强后的样本在真实的测试数据下，准确率比增强前的样本高了很多，说明数据增强起到了很大的作用。

### 16.6.3 多样本合成法

#### SMOTE

SMOTE,Synthetic Minority Over-sampling Technique$^{[1]}$，通过人工合成新样本来处理样本不平衡问题，提升分类器性能。

类不平衡现象是数据集中各类别数量不近似相等。如果样本类别之间相差很大，会影响分类器的分类效果。假设小样本数据数量极少，仅占总体的1%，所能提取的相应特征也极少，即使小样本被错误地全部识别为大样本，在经验风险最小化策略下的分类器识别准确率仍能达到99%，但在验证环节分类效果不佳。

基于插值的SMOTE方法为小样本类合成新的样本，主要思路为：

1. 定义好特征空间，将每个样本对应到特征空间中的某一点，根据样本不平衡比例确定采样倍率N；
2. 对每一个小样本类样本$(x,y)$，按欧氏距离找K个最近邻样本，从中随机选取一个样本点，假设选择的近邻点为$(x_n,y_n)$。在特征空间中样本点与最近邻样本点的连线段上随机选取一点作为新样本点，满足以下公式:

$$(x_{new},y_{new})=(x,y)+rand(0,1)\times ((x_n-x),(y_n-y))$$

3. 重复选取取样，直到大、小样本数量平衡。

在`python`中，SMOTE算法已经封装到了`imbalanced-learn`库中。

#### SamplePairing

SamplePairing$^{[2]}$方法的处理流程如图16-35所示，从训练集中随机抽取两张图片分别经过基础数据增强操作（如随机翻转等）处理后经像素取平均值的形式叠加合成一个新的样本，标签为原样本标签中的一种。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/16/sample_pairing.png" />

图16-35 SamplePairing方法的处理流程

经SamplePairing处理后可使训练集的规模从N扩增到N*N，在CPU上也能完成处理。

训练过程是交替禁用与使用SamplePairing处理操作的结合：

1. 使用传统的数据增强训练网络，不使用SamplePairing 数据增强训练。
2. 在ILSVRC数据集上完成一个epoch或在其他数据集上完成100个epoch后，加入SamplePairing 数据增强训练。
3. 间歇性禁用 SamplePairing。对于 ILSVRC 数据集，为其中的300000 个图像启用SamplePairing，然后在接下来的100000个图像中禁用它。对于其他数据集，在开始的8个epoch中启用，在接下来的2个epoch中禁止。
4. 在训练损失函数和精度稳定后进行微调，禁用SamplePairing。

实验结果表明，因SamplePairing数据增强操作可能引入不同标签的训练样本，导致在各数据集上使用SamplePairing训练的误差明显增加，而在检测误差方面使用SamplePairing训练的验证误差有较大幅度降低。

尽管SamplePairing思路简单，性能上提升效果可观，符合奥卡姆剃刀原理，遗憾的是的可解释性不强，目前尚缺理论支撑。目前仅有图片数据的实验，还需下一步的实验与解读。

#### Mixup

Mixup$^{[3]}$是基于邻域风险最小化（VRM）原则的数据增强方法，使用线性插值得到新样本数据。在邻域风险最小化原则下，根据特征向量线性插值将导致相关目标线性插值的先验知识，可得出简单且与数据无关的mixup公式：

$$
x_n=\lambda x_i + (1-\lambda)x_j \\\\
y_n=\lambda y_i + (1-\lambda)y_j
$$

其中$(x_n，y_n)$是插值生成的新数据，$(x_i,y_i)$和$(x_j，y_j)$是训练集中随机选取的两个数据，λ的取值满足贝塔分布，取值范围介于0到1，超参数α控制特征目标之间的插值强度。

Mixup的实验丰富，实验结果表明可以改进深度学习模型在ImageNet数据集、CIFAR数据集、语音数据集和表格数据集中的泛化误差，降低模型对已损坏标签的记忆，增强模型对对抗样本的鲁棒性和训练对抗生成网络的稳定性。

Mixup处理实现了边界模糊化，提供平滑的预测效果，增强模型在训练数据范围之外的预测能力。随着超参数α增大，实际数据的训练误差就会增加，而泛化误差会减少。说明Mixup隐式地控制着模型的复杂性。随着模型容量与超参数的增加，训练误差随之降低。

尽管有着可观的效果改进，但mixup在偏差—方差平衡方面尚未有较好的解释。在其他类型的有监督学习、无监督、半监督和强化学习中，Mixup还有很大的发展空间。

# miniFramework实现手写数字的识别

### 代码

```
# Copyright (c) Microsoft. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.

from matplotlib import pyplot as plt
import numpy as np
from PIL import Image

from HelperClass2.NeuralNet_3_0 import *

def ReadImage(img_file_name):
    img = Image.open(img_file_name)
    out1 = img.convert('L')
    out2 = out1.resize((28,28))
    a = np.array(out2)
    b = 255 - a
    x_max = np.max(b)
    x_min = np.min(b)
    X_NEW = (b - x_min)/(x_max-x_min)
    plt.cla()
    plt.imshow(X_NEW)
    plt.plot()
    return X_NEW.reshape(1,-1)

def Inference(img_array):
    output = net.inference(img_array)
    n = np.argmax(output)
    print("------recognize result is: -----", n)

def on_key_press(event):
    img_file_name = "handwriting.png"
    print(event.key)
    if event.key == 'enter':
        plt.axis('off')
        plt.savefig(img_file_name)
        plt.axis('on')
        img_array = ReadImage(img_file_name)
        Inference(img_array)
    elif event.key == 'backspace':
        plt.cla()
        plt.axis([0,1,0,1])
        ax.figure.canvas.draw()
    #end if

def on_mouse_press(event):
    global startx, starty, isdraw
    print(isdraw)
    isdraw = True
    startx = event.xdata
    starty = event.ydata
    print("press:{0},{1}", startx, starty)
    
def on_mouse_release(event):
    global isdraw, startx, starty
    print("release:", event.xdata, event.ydata, isdraw)
    isdraw = False

def on_mouse_move(event):
    global isdraw, startx, starty
    if isdraw:
        endx = event.xdata        
        endy = event.ydata        
        x1 = [startx, endx]
        y1 = [starty, endy]
        ax.plot(x1, y1, color='black', linestyle='-', linewidth='40')
        ax.figure.canvas.draw()
        startx = endx
        starty = endy
    # end if

def LoadNet():
    n_input = 784
    n_hidden1 = 64
    n_hidden2 = 16
    n_output = 10
    eta = 0.2
    eps = 0.01
    batch_size = 128
    max_epoch = 40

    hp = HyperParameters_3_0(
        n_input, n_hidden1, n_hidden2, n_output, 
        eta, max_epoch, batch_size, eps, 
        NetType.MultipleClassifier, 
        InitialMethod.Xavier)
    net = NeuralNet_3_0(hp, "MNIST_64_16")
    net.LoadResult()
    return net
   
if __name__ == "__main__":
    isdraw = False
    startx, starty = 0, 0

    print("need to run level3 first to get result")
    print("============================================================================")
    print("handwriting a digit, then press enter to recognize, press backspace to clear")
    print("resize the window to square, say, height == width")
    print("the handwriting should full fill the window")
    print("============================================================================")

    net = LoadNet()

    fig, ax = plt.subplots()
    fig.canvas.mpl_connect('key_press_event', on_key_press)
    fig.canvas.mpl_connect('button_release_event', on_mouse_release)
    fig.canvas.mpl_connect('button_press_event', on_mouse_press)
    fig.canvas.mpl_connect('motion_notify_event', on_mouse_move)
    
    plt.axis([0,1,0,1])
    plt.show()
```

## 运行结果如下：

![markdown](https://i0.hdslb.com/bfs/album/babfb01c796e0c46199490481032e9cd59be35a8.png)


# 总结

通过学习人工智能AI的课程，从基础的神经元，神经网络学起，掌握了基础的AI知识，可以通过使用python进行简单地编译，绘制出相应的图像，在AI的学习过程中，了解了AI的发展历程，以及对其未来发展的展望，AI是一门综合型的学科，涵盖的内容广泛，知识信息量大，这些无不是学习过程中的难点和问题，为此，我也是通过查阅资料，在书上寻找知识，在网上搜说有价值的资料，来学习这一门课程，对于AI的神经网络，梯度下降，反向传播等关键知识模块，都是在书籍与网络上反复寻求最优解，随之而来的就是深深地思考，接下来就是动手实验，用老师提供的资料与代码，在python上进行绘制图像，小心求证，大胆质疑。

最后，得出来一些学习过程中的感悟，AI这门学科门槛是很高的，从数学角度来说，就是涵盖了大学高等数学几乎所有的知识点，从偏微分到概率论，因为在使用AI解决实际问题时，就是会用到这些数学知识，还有许许多多复杂的公式，无不需要研究者可以熟练地运用，这都是难点，其次，就是编程，如何将公式转化为代码，最后跑出来，这个也是难度所在，所以说AI是门槛很高的一门学科，在将实际问题转换为数学模型时，又需要制作者有很强的分析能力，来分析问题的模型与框架，思考正反馈，负反馈等实际生活中常见的问题，这都是对创作者极高的要求。

在我对AI的学习中，我对AI有了更深一步的认知，未来的AI发展也是定当迈入新的时期，我也希望在以后的学习中，继续学习AI，关注AI的发展和阶跃，我也相信在数字化的浪潮中，AI定将在新基建，新动能上发挥重要的最用，感谢这一段时间老师的教导，带我走进了AI世界的大门，在后面的学习中，我还会持续关注AI未来的动向，学习AI的相关最新知识，提高自身的能力，为社会经济数字化创造价值》