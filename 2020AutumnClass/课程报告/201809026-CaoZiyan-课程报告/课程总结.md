# 课程总结

## 1.神经网络的基本工作原理

### 神经网络模型

神经网络由<font color=#FF000 >**基本的神经元**</font>组成，下图就是一个神经元的数学/计算模型，便于我们用程序来实现。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/1/image5.png" width="500" />

- <font color=#000FF >**输入 input**</font>

$(x_1,x_2,x_3)$ 是外界输入信号，一般是一个训练数据样本的多个属性

- <font color=#000FF >**权重 weights**</font>

$(w_1,w_2,w_3)$ 是每个输入信号的权重值

- <font color=#000FF >**偏移 bias**</font>
  
- <font color=#000FF >**求和计算 sum**</font>

- <font color=#000FF >**激活函数 activation**</font>

### 训练流程

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/1/TrainFlow.png" />

### 激活函数

	1.处处可导
	2.非线性
	3.可微性
	4.单调性
	5.输出值范围（可控）
	6.计算简单
	7.归一化
	8.函数值约等变量

- <font color=#000FF >**Sigmoid函数**</font>

    1.连续可微
	2.单调递增
	3.输出值为0到1之内
 	4.求导合适

### 损失函数

<font color=#000FF >**交叉熵**</font>

    $loss = ylog(\hat{y}_n)+(1-y)\log (1-\hat{y}_n)$

<font color=#000FF >**均方差**</font>

    $loss = \frac{1}{n}\sum_{n=1}^{n=\infty}(\hat{x}_i-x_i)^2$

## 2.反向传播与梯度下降

### 反向传播与梯度下降的基本工作原理：

1. 初始化；
2. 正向计算；
3. 损失函数为我们提供了计算损失的方法；
4. 梯度下降是在损失函数基础上向着损失最小的点靠近而指引了网络权重调整的方向；
5. 反向传播把损失值反向传给神经网络的每一层，让每一层都根据损失值反向调整权重；
6. Go to 2，直到精度足够好（比如损失函数值小于 $0.001$）。

### 梯度下降法

<font color=#000FF >**要求**：</font>

先随机的确定权值和偏置，计算出损失函数，然后再通过梯度下降的办法，在反向修改权重，让损失函数达到最小值

<font color=#000FF >**原理**：</font>：学习率的大小需要自己进行定义

```python
#当损失函数形式为均值平方差时
def __mothd(X,Y,w,b,eta):
#w,b随机，eta为固定值
    for i in range(reader.num_train):
#reader.num_train为reader的函数
    x = X[i]
    y = Y[i]
    z = x*w+b
    dz = z - y
    dw = dz*x
    w = w - eta*dw
    b = b - eta*dz
```

“梯度下降”包含了两层含义：

1. 梯度：函数当前位置的最快上升点；
2. 下降：与导数相反的方向，用数学语言描述就是那个减号。

亦即与上升相反的方向运动，就是下降。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/2/gd_concept.png" ch="500" />

## 3.一般框架

- 1.定义神经元结构
  
    - 神经元的输入和输出的方式和个数
    - 神经元的偏置和激活函数的选择

- 2.定义神经网络

    - 输入层 ：<font color=#000FF >**输入的特征数**</font>
    - 隐层： <font color=#000FF >**数目可多个**</font>
    - 输出层： <font color=#000FF >**类别数目**</font>
  
- 3.损失函数定义
    
    - 选择与问题相对应的损失函数

        **如**：<font color=#000FF >线性回归问题使用均方差公式，二分类使用交叉熵公式</font>

**DNN框架搭建**：

``` python
import numpy as np
class NeuralNet(object):
    #功能定义
    def __init__(self,num,eta,max_epoch,bat_size):
        #神经网络层
        self.layers = []#容纳神经网络各层
        self.layer_num = num #神经网络层数
        #神经网络运行参数
        self.eta = eta #学习率
        self.max_epoch = max_epoch #最大回合数
        self.bat_size = bat_size#每批数
        #损失函数
        self.j#损失函数值
        self.j_his#损失函数历史值
        self.j_graph#损失函数画图许可
    return print("Neural init is OK")
    #方法定义
    def Add_layer(self,lay): #神经网络层的添加
        len = self.layers.lenth()
        if len < self.layer_num:
            self.layers[len] = lay
        else print("神经网络层数已达上限")
        return print("lay添加成功")
    def Com_neural(self,X,i):#调用i层线性计算方法
        Z = np.dot(self.layer[i].w,X) + self.layer[i].b
        return Z
    def Back_method(self,Y,A):#反向传播
        dZ = A - Y
        dW = np.dot(A.dZ)
        dB = dZ
        return dW,dB
    def layer_u(self,dW,dB,i)：#本层的更新参数
        w = self.layers[i].w
        b = self.layers[i].b
        w = w - eta*dW
        b = b - eta*dB
        self.layers[i].w = w
        self.layers[i].b = b
    def train_N(self,X,Y):#训练
        A1 = X
        A2 = array([])
        A3 = Y
        for i in range(self.layer_num):
            Z = Com_neural(A1,i)
            A1 = Mothd_act.Identity(Z)
            A2[i] = A1
            A3[i] = Z
        for i in range(self.layer_num):
            dW,dB = Back_method(A3[self.layer_num-i],A2[self.layer_num-i])
            layer_u(dW,dB,i)

```

# 手写体识别

```cpp

using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.Linq;
using System.Threading.Tasks;
using Windows.UI.Xaml.Controls;
using Windows.Graphics.Imaging;
using Windows.UI.Xaml.Media.Imaging;
using Windows.Media;

namespace MNIST_Demo
{
    public class Helper
    {
        VideoFrame cropped_vf = null;

        public async Task<VideoFrame> GetHandWrittenImage(Grid grid)
        {
            RenderTargetBitmap renderBitmap = new RenderTargetBitmap();

            await renderBitmap.RenderAsync(grid);
            var buffer = await renderBitmap.GetPixelsAsync();
            var softwareBitmap = SoftwareBitmap.CreateCopyFromBuffer(buffer, BitmapPixelFormat.Bgra8, renderBitmap.PixelWidth, renderBitmap.PixelHeight, BitmapAlphaMode.Ignore);

            buffer = null;
            renderBitmap = null;

            VideoFrame vf = VideoFrame.CreateWithSoftwareBitmap(softwareBitmap);
            await CropAndDisplayInputImageAsync(vf);

            return cropped_vf;
        }


        private async Task CropAndDisplayInputImageAsync(VideoFrame inputVideoFrame)
        {
            bool useDX = inputVideoFrame.SoftwareBitmap == null;

            BitmapBounds cropBounds = new BitmapBounds();
            uint h = 28;
            uint w = 28;
            var frameHeight = useDX ? inputVideoFrame.Direct3DSurface.Description.Height : inputVideoFrame.SoftwareBitmap.PixelHeight;
            var frameWidth = useDX ? inputVideoFrame.Direct3DSurface.Description.Width : inputVideoFrame.SoftwareBitmap.PixelWidth;

            var requiredAR = ((float)28 / 28);
            w = Math.Min((uint)(requiredAR * frameHeight), (uint)frameWidth);
            h = Math.Min((uint)(frameWidth / requiredAR), (uint)frameHeight);
            cropBounds.X = (uint)((frameWidth - w) / 2);
            cropBounds.Y = 0;
            cropBounds.Width = w;
            cropBounds.Height = h;

            cropped_vf = new VideoFrame(BitmapPixelFormat.Bgra8, 28, 28, BitmapAlphaMode.Ignore);

            await inputVideoFrame.CopyToAsync(cropped_vf, cropBounds, null);
        }

    }
}

```

测试如下：

![](/课程总结/0.png)

![](/课程总结/4.png)

![](/课程总结/5.png)

![](/课程总结/1.png)

![](/课程总结/6.png)

总结：这次代码测试，识别了我的幸运数字04以及我的生日516。我写的是法语版数字（目前区别主要可以在0和6中看出来），没想到依然能被识别出来。感叹人工智能的强大。同时感觉需要进行更多的训练集训练模型，从而进一步完善出来。

可以调小单次权重变化值，当然也有可能或存在过拟合的情况。（仅为猜测，最好进行大量的实践找出更准确的原因。这个任务就拜托老师了，我真的太困了~）

![](/课程总结/困.jpg)
